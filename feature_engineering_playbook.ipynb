{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Feature Engineering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "\n",
        "- 核心原则：\n",
        "  1) **先明确数据切分规则**（时间序列 vs i.i.d.）再做任何会“看见未来”的特征；\n",
        "  2) 用 **Pipeline / ColumnTransformer** 把预处理和模型绑定，防止泄漏；\n",
        "  3) 特征工程优先级：**(a) 正确性与不泄漏** > (b) 解释性 > (c) 复杂度。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 0. 常用 import"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.model_selection import train_test_split, TimeSeriesSplit\n",
        "from sklearn.metrics import mean_squared_error, roc_auc_score, accuracy_score\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler, RobustScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.feature_selection import mutual_info_regression, mutual_info_classif\n",
        "from sklearn.inspection import permutation_importance\n",
        "\n",
        "# 常见 baseline 模型\n",
        "from sklearn.linear_model import Ridge, Lasso, LogisticRegression\n",
        "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier, GradientBoostingRegressor, GradientBoostingClassifier\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. 快速体检：列类型、缺失、常量、唯一值"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "def quick_profile(df: pd.DataFrame, max_uniques=20) -> pd.DataFrame:\n",
        "    out = []\n",
        "    n = len(df)\n",
        "    for c in df.columns:\n",
        "        s = df[c]\n",
        "        nunique = s.nunique(dropna=True)\n",
        "        out.append({\n",
        "            \"col\": c,\n",
        "            \"dtype\": str(s.dtype),\n",
        "            \"missing_pct\": float(s.isna().mean()),\n",
        "            \"nunique\": int(nunique),\n",
        "            \"sample_uniques\": (s.dropna().unique()[:max_uniques]).tolist() if nunique <= max_uniques else None,\n",
        "            \"is_constant\": bool(nunique <= 1),\n",
        "        })\n",
        "    prof = pd.DataFrame(out).sort_values([\"missing_pct\",\"nunique\"], ascending=[False, True])\n",
        "    return prof\n",
        "\n",
        "# 用法：\n",
        "# prof = quick_profile(df)\n",
        "# prof.head(30)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. 先定切分：i.i.d. vs 时间序列"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "### 2.1 i.i.d.（常规随机切分）\n",
        "- 适用：样本之间独立同分布，或数据已打乱且没有时间泄漏风险。\n",
        "- 注意：类别不均衡可用 `stratify=y`。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# X_train, X_test, y_train, y_test = train_test_split(\n",
        "#     X, y, test_size=0.2, random_state=42, stratify=y  # 分类可用\n",
        "# )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "### 2.2 时间序列（严格按时间切分）\n",
        "- 适用：金融/电力/需求等，**预测未来**。\n",
        "- 关键：训练集时间必须早于测试集；滚动验证用 `TimeSeriesSplit`。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "def time_train_test_split(df, time_col, test_size=0.2):\n",
        "    df = df.sort_values(time_col).reset_index(drop=True)\n",
        "    n = len(df)\n",
        "    cut = int(np.floor(n * (1 - test_size)))\n",
        "    return df.iloc[:cut].copy(), df.iloc[cut:].copy()\n",
        "\n",
        "# 用法：\n",
        "# train_df, test_df = time_train_test_split(df, \"date\", test_size=0.2)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. 列分组：数值/类别/日期时间（自动识别）"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "def infer_column_types(df: pd.DataFrame, target=None, time_col=None):\n",
        "    cols = [c for c in df.columns if c != target]\n",
        "    if time_col is not None and time_col in cols:\n",
        "        cols.remove(time_col)\n",
        "\n",
        "    num_cols = [c for c in cols if pd.api.types.is_numeric_dtype(df[c])]\n",
        "    cat_cols = [c for c in cols if (not pd.api.types.is_numeric_dtype(df[c]))]\n",
        "\n",
        "    # 把“数字但其实是ID”的列挑出来：nunique 很大、且接近样本数\n",
        "    maybe_id = []\n",
        "    for c in num_cols:\n",
        "        ratio = df[c].nunique(dropna=True) / max(1, len(df))\n",
        "        if ratio > 0.8:\n",
        "            maybe_id.append(c)\n",
        "\n",
        "    return num_cols, cat_cols, maybe_id\n",
        "\n",
        "# 用法：\n",
        "# num_cols, cat_cols, maybe_id = infer_column_types(df, target=\"y\", time_col=\"date\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. sklearn Pipeline 模板（强烈建议：面试时就按这个来）"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "### 4.1 通用预处理\n",
        "- 数值：缺失填充（median）+ 标准化/鲁棒缩放\n",
        "- 类别：缺失填充（most_frequent）+ OneHotEncoder\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "def build_preprocessor(num_cols, cat_cols, scaler=\"standard\"):\n",
        "    if scaler == \"standard\":\n",
        "        scaler_step = StandardScaler()\n",
        "    elif scaler == \"robust\":\n",
        "        scaler_step = RobustScaler()\n",
        "    else:\n",
        "        scaler_step = \"passthrough\"\n",
        "\n",
        "    numeric_pipe = Pipeline(steps=[\n",
        "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
        "        (\"scaler\", scaler_step),\n",
        "    ])\n",
        "\n",
        "    categorical_pipe = Pipeline(steps=[\n",
        "        (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
        "        (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\", sparse=False)),\n",
        "    ])\n",
        "\n",
        "    pre = ColumnTransformer(\n",
        "        transformers=[\n",
        "            (\"num\", numeric_pipe, num_cols),\n",
        "            (\"cat\", categorical_pipe, cat_cols),\n",
        "        ],\n",
        "        remainder=\"drop\",\n",
        "        verbose_feature_names_out=False\n",
        "    )\n",
        "    return pre\n",
        "\n",
        "# 用法：\n",
        "# pre = build_preprocessor(num_cols, cat_cols, scaler=\"robust\")\n",
        "# model = Ridge(alpha=1.0)\n",
        "# pipe = Pipeline([(\"pre\", pre), (\"model\", model)])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. 时间特征：日期拆解 + 周期编码（对树模型/线性模型都友好）"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "def add_datetime_features(df: pd.DataFrame, time_col: str, drop_original=False):\n",
        "    out = df.copy()\n",
        "    t = pd.to_datetime(out[time_col])\n",
        "    out[f\"{time_col}_year\"] = t.dt.year\n",
        "    out[f\"{time_col}_month\"] = t.dt.month\n",
        "    out[f\"{time_col}_day\"] = t.dt.day\n",
        "    out[f\"{time_col}_dow\"] = t.dt.dayofweek  # 0=Mon\n",
        "    out[f\"{time_col}_hour\"] = t.dt.hour\n",
        "    out[f\"{time_col}_is_month_end\"] = t.dt.is_month_end.astype(int)\n",
        "    out[f\"{time_col}_is_month_start\"] = t.dt.is_month_start.astype(int)\n",
        "\n",
        "    # 周期编码（对线性模型更重要）\n",
        "    out[f\"{time_col}_dow_sin\"] = np.sin(2*np.pi*out[f\"{time_col}_dow\"]/7)\n",
        "    out[f\"{time_col}_dow_cos\"] = np.cos(2*np.pi*out[f\"{time_col}_dow\"]/7)\n",
        "    out[f\"{time_col}_month_sin\"] = np.sin(2*np.pi*out[f\"{time_col}_month\"]/12)\n",
        "    out[f\"{time_col}_month_cos\"] = np.cos(2*np.pi*out[f\"{time_col}_month\"]/12)\n",
        "\n",
        "    if drop_original:\n",
        "        out = out.drop(columns=[time_col])\n",
        "    return out\n",
        "\n",
        "# 用法：\n",
        "# df2 = add_datetime_features(df, \"date\", drop_original=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. lag / rolling 特征"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "> 任何 rolling/lag 特征都必须只用 “过去” 信息。  \n",
        "> 具体实现：先按时间排序；对每个实体（如 instrument / meter / region）分组后 `shift()`；rolling 用 `shift(1).rolling(...)`。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "def add_lag_features(\n",
        "    df: pd.DataFrame,\n",
        "    group_cols,\n",
        "    time_col: str,\n",
        "    value_cols,\n",
        "    lags=(1,2,5),\n",
        "):\n",
        "    out = df.sort_values(group_cols + [time_col]).copy()\n",
        "    g = out.groupby(group_cols, sort=False)\n",
        "    for v in value_cols:\n",
        "        for L in lags:\n",
        "            out[f\"{v}_lag{L}\"] = g[v].shift(L)\n",
        "    return out\n",
        "\n",
        "def add_rolling_features(\n",
        "    df: pd.DataFrame,\n",
        "    group_cols,\n",
        "    time_col: str,\n",
        "    value_cols,\n",
        "    windows=(3,7,14),\n",
        "    stats=(\"mean\",\"std\",\"min\",\"max\")\n",
        "):\n",
        "    out = df.sort_values(group_cols + [time_col]).copy()\n",
        "    g = out.groupby(group_cols, sort=False)\n",
        "    for v in value_cols:\n",
        "        base = g[v].shift(1)  # shift(1) 保证 rolling 不用到当前/未来\n",
        "        for w in windows:\n",
        "            r = base.rolling(window=w, min_periods=max(2, w//3))\n",
        "            if \"mean\" in stats:\n",
        "                out[f\"{v}_roll{w}_mean\"] = r.mean().reset_index(level=0, drop=True)\n",
        "            if \"std\" in stats:\n",
        "                out[f\"{v}_roll{w}_std\"] = r.std().reset_index(level=0, drop=True)\n",
        "            if \"min\" in stats:\n",
        "                out[f\"{v}_roll{w}_min\"] = r.min().reset_index(level=0, drop=True)\n",
        "            if \"max\" in stats:\n",
        "                out[f\"{v}_roll{w}_max\"] = r.max().reset_index(level=0, drop=True)\n",
        "    return out\n",
        "\n",
        "# 用法示例（按 instrument 分组）：\n",
        "# df = add_lag_features(df, group_cols=[\"instrument\"], time_col=\"date\", value_cols=[\"price\"], lags=(1,2,5,10))\n",
        "# df = add_rolling_features(df, group_cols=[\"instrument\"], time_col=\"date\", value_cols=[\"price\"], windows=(5,20), stats=(\"mean\",\"std\"))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. 比率/差分/交互"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "def add_ratio_diff_features(df: pd.DataFrame, pairs):\n",
        "    \"\"\"pairs: list of (a,b) column name tuples. 生成 a_minus_b, a_over_b\"\"\"\n",
        "    out = df.copy()\n",
        "    eps = 1e-9\n",
        "    for a,b in pairs:\n",
        "        out[f\"{a}_minus_{b}\"] = out[a] - out[b]\n",
        "        out[f\"{a}_over_{b}\"] = out[a] / (out[b].abs() + eps)\n",
        "    return out\n",
        "\n",
        "# 用法：\n",
        "# df = add_ratio_diff_features(df, pairs=[(\"bid\",\"ask\"), (\"high\",\"low\")])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. 高基数类别"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "### 8.1 One-Hot 的问题\n",
        "- 类别数很多（例如上万）会导致维度膨胀、内存和训练时间爆炸。\n",
        "- 但如果样本量不大，且类别对 target 很关键，One-Hot 仍可能有效。\n",
        "\n",
        "### 8.2 实战策略（按优先级）\n",
        "1) **频次截断**：只保留 top-K 类别，其余归为 'OTHER'\n",
        "2) **哈希技巧**：`FeatureHasher`（如果可用）\n",
        "3) **目标编码**：需严格做 *out-of-fold*（否则严重泄漏）\n",
        "4) **树模型**：某些树模型能吃 raw id（但在 sklearn 里一般还是需要编码）\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "def topk_category(df: pd.DataFrame, col: str, k=50, other=\"__OTHER__\"):\n",
        "    out = df.copy()\n",
        "    vc = out[col].value_counts(dropna=False)\n",
        "    keep = set(vc.index[:k])\n",
        "    out[col] = out[col].where(out[col].isin(keep), other)\n",
        "    return out\n",
        "\n",
        "# 用法：\n",
        "# df = topk_category(df, \"sector\", k=100)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. 轻量特征筛选：Mutual Information + Permutation Importance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "- **Mutual Information**：很快，适合初筛；对非线性关系也敏感。\n",
        "- **Permutation Importance**：更贴近模型真实贡献；但更慢，最好在一个 baseline 模型上做。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "def mi_rank(X: pd.DataFrame, y, task=\"regression\", discrete_features=\"auto\", random_state=42):\n",
        "    # 这里要求 X 全是数值（所以通常在 OneHot 后做）\n",
        "    X_ = np.asarray(X)\n",
        "    y_ = np.asarray(y)\n",
        "    if task == \"regression\":\n",
        "        mi = mutual_info_regression(X_, y_, discrete_features=discrete_features, random_state=random_state)\n",
        "    else:\n",
        "        mi = mutual_info_classif(X_, y_, discrete_features=discrete_features, random_state=random_state)\n",
        "    return np.array(mi)\n",
        "\n",
        "def permutation_rank(pipe, X_valid, y_valid, scoring=None, n_repeats=5, random_state=42):\n",
        "    r = permutation_importance(pipe, X_valid, y_valid, scoring=scoring, n_repeats=n_repeats, random_state=random_state)\n",
        "    return r.importances_mean, r.importances_std\n",
        "\n",
        "# 用法（Permutation）：\n",
        "# pipe.fit(X_train, y_train)\n",
        "# imp_mean, imp_std = permutation_rank(pipe, X_test, y_test, scoring=\"neg_root_mean_squared_error\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10. 落地流程"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "1) **Baseline**：最简单的 Pipeline（数值+类别） + Ridge/LogReg 或 RandomForest  \n",
        "2) **加时间特征**：日期拆解 + (如果有实体) lag/rolling  \n",
        "3) **加少量手工特征**：差分/比率/交互（最易解释）  \n",
        "4) **做验证**：TimeSeriesSplit 或明确的时间切分；报告指标 + 误差分布  \n",
        "5) **解释模型**：Top features（Permutation）+ 直观解释（为什么合理）  \n",
        "6) **写进 PPT**：Data&Split、Features&Model、Results&Next steps\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 11. 示例"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# 假设：df 包含 target 列 y；时间列 date；可能还有 instrument/entity 列\n",
        "# df = pd.read_csv(\"your_data.csv\")\n",
        "\n",
        "# 1) 时间特征\n",
        "# df = add_datetime_features(df, time_col=\"date\", drop_original=False)\n",
        "\n",
        "# 2) lag/rolling（如果是面板数据：instrument x time）\n",
        "# df = add_lag_features(df, group_cols=[\"instrument\"], time_col=\"date\", value_cols=[\"price\"], lags=(1,2,5))\n",
        "# df = add_rolling_features(df, group_cols=[\"instrument\"], time_col=\"date\", value_cols=[\"price\"], windows=(5,20))\n",
        "\n",
        "# 3) 切分（严格按时间）\n",
        "# train_df, test_df = time_train_test_split(df, time_col=\"date\", test_size=0.2)\n",
        "# y_train = train_df[\"y\"]; X_train = train_df.drop(columns=[\"y\"])\n",
        "# y_test  = test_df[\"y\"];  X_test  = test_df.drop(columns=[\"y\"])\n",
        "\n",
        "# 4) 列类型\n",
        "# num_cols, cat_cols, maybe_id = infer_column_types(X_train, target=None, time_col=\"date\")\n",
        "# print(\"maybe_id:\", maybe_id)\n",
        "\n",
        "# 5) Pipeline + 模型\n",
        "# pre = build_preprocessor(num_cols=num_cols, cat_cols=cat_cols, scaler=\"robust\")\n",
        "# pipe = Pipeline([(\"pre\", pre), (\"model\", Ridge(alpha=1.0))])\n",
        "\n",
        "# 6) 训练与评估（回归）\n",
        "# pipe.fit(X_train, y_train)\n",
        "# pred = pipe.predict(X_test)\n",
        "# rmse = mean_squared_error(y_test, pred, squared=False)\n",
        "# print(\"RMSE:\", rmse)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "## 12. 常见坑\n",
        "- **Leakage**：rolling 里忘记 `shift(1)`；目标编码不做 OOF；标准化在全数据上 fit。\n",
        "- **时间切分**：用 train_test_split 随机打乱导致未来信息进入训练。\n",
        "- **类别处理**：测试集出现新类别 → OneHotEncoder 要 `handle_unknown=\"ignore\"`。\n",
        "- **缺失值**：树模型有时能处理，但 sklearn 大多数模型不接受 NaN → 统一 impute。\n",
        "- **ID 列**：高基数数值列（看着像连续，其实是ID）会害死线性模型；建议丢弃或当类别处理。\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
