{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02cc1ae4",
   "metadata": {},
   "source": [
    "# Spiky / Discretized Numeric Features（离散尖刺）处理备忘\n",
    "\n",
    "**场景**：某些“数值型”特征看起来是 `float/int`，但分布呈现明显 **spikes**（少数取值占据大量样本），常见成因：**rounding / bucket / tick size / 报表口径离散化**。\n",
    "\n",
    "**核心结论**：这类变量不再满足“连续可微/平滑”的直觉；将其当作纯连续变量会诱导模型做不合理的插值/外推。处理时优先考虑 **categorical / ordinal / target encoding / 树模型** 等更贴近生成机制的方法。\n",
    "\n",
    "本 notebook 作为 dataset interview 的 quick reference：\n",
    "- 如何识别 spiky\n",
    "- 如何快速判断该走 categorical/ordinal/target encoding\n",
    "- 如何在时序切分下避免泄漏\n",
    "- 如何在 presentation 里用一句话解释处理逻辑"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce16c99d",
   "metadata": {},
   "source": [
    "## 0. 环境与工具\n",
    "\n",
    "默认使用：`numpy, pandas, scikit-learn, matplotlib`（面试环境通常具备）。  \n",
    "如需额外包（例如 `category_encoders`），用 `pip install`（现场以可用性为准）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac3ed2b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f628e11",
   "metadata": {},
   "source": [
    "## 1) Spiky 的快速体征（5分钟 checklist）\n",
    "\n",
    "一个变量满足任意多条，即可判定为“高度离散/尖刺”：\n",
    "- `n_unique` 很小（例如 < 50 / < 100），但样本量很大\n",
    "- `value_counts()` 前几个取值占比离谱（例如 top-5 占比 > 50%）\n",
    "- 小数位“锁死”（例如全是 0.01 的倍数、全是整数、全是 0.5 的倍数）\n",
    "- 直方图呈现“针状”（mass 集中在少数网格点）\n",
    "- 时序上表现为：长时间不动，偶尔跳一下（报价 tick / bucket 更新）\n",
    "\n",
    "下面的函数输出：\n",
    "- unique 数、top-k 占比、最常见取值\n",
    "- 小数粒度（近似）\n",
    "- 分布图（直方图 + 取值条形图）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46219142",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def _decimal_step_estimate(x, max_n=5000):\n",
    "    \"\"\"\n",
    "    Estimate discretization step (heuristic).\n",
    "    Method: sample -> unique -> sort -> diffs -> mode of positive diffs.\n",
    "    \"\"\"\n",
    "    x = pd.Series(x).dropna().astype(float)\n",
    "    if x.empty:\n",
    "        return np.nan\n",
    "    if len(x) > max_n:\n",
    "        x = x.sample(max_n, random_state=0)\n",
    "    vals = np.sort(x.unique())\n",
    "    if len(vals) < 3:\n",
    "        return np.nan\n",
    "    diffs = np.diff(vals)\n",
    "    diffs = diffs[np.isfinite(diffs) & (diffs > 0)]\n",
    "    if len(diffs) == 0:\n",
    "        return np.nan\n",
    "    diffs_r = np.round(diffs, 12)\n",
    "    step = pd.Series(diffs_r).value_counts().idxmax()\n",
    "    return float(step)\n",
    "\n",
    "def spiky_report(df, col, topk=10, bins=50, show_plots=True):\n",
    "    s = df[col]\n",
    "    n = len(s)\n",
    "    nunique = s.nunique(dropna=True)\n",
    "    vc = s.value_counts(dropna=True)\n",
    "    top_share = vc.head(topk).sum() / vc.sum() if vc.sum() > 0 else np.nan\n",
    "    step = _decimal_step_estimate(s)\n",
    "\n",
    "    print(f\"[{col}] n={n:,}  nunique={nunique:,}  top{topk}_share={top_share:.3f}  est_step={step}\")\n",
    "    print(\"Top values:\")\n",
    "    display(vc.head(topk))\n",
    "\n",
    "    if not show_plots:\n",
    "        return\n",
    "\n",
    "    # Histogram\n",
    "    plt.figure()\n",
    "    s_float = pd.to_numeric(s, errors=\"coerce\")\n",
    "    plt.hist(s_float.dropna().values, bins=bins)\n",
    "    plt.title(f\"{col} histogram\")\n",
    "    plt.xlabel(col)\n",
    "    plt.ylabel(\"count\")\n",
    "    plt.show()\n",
    "\n",
    "    # Bar plot when nunique is small\n",
    "    if nunique <= 60:\n",
    "        plt.figure()\n",
    "        vc.head(min(30, nunique)).sort_index().plot(kind=\"bar\")\n",
    "        plt.title(f\"{col} top values barplot (sorted by value)\")\n",
    "        plt.xlabel(col)\n",
    "        plt.ylabel(\"count\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64403fb3",
   "metadata": {},
   "source": [
    "### 1.1 演示（用模拟数据）\n",
    "\n",
    "下面造几种典型 spiky：\n",
    "- rounding：连续值四舍五入到 0.05\n",
    "- bucket：先分箱再映射为箱中心/等级\n",
    "- 混合：大量 0 + 少量连续值（“零尖刺”）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b01cbde",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rng = np.random.default_rng(0)\n",
    "n = 20000\n",
    "\n",
    "df_demo = pd.DataFrame({\n",
    "    \"x_round_0p05\": np.round(rng.normal(0, 1, n) / 0.05) * 0.05,\n",
    "    \"x_bucket_10\": pd.cut(rng.normal(0, 1, n), bins=10, labels=False).astype(float),\n",
    "    \"x_zero_spike\": (rng.random(n) < 0.7).astype(float) * 0.0 + (rng.random(n) >= 0.7) * rng.normal(0, 1, n),\n",
    "})\n",
    "df_demo[\"y_reg\"] = 0.5*df_demo[\"x_round_0p05\"] + 0.2*df_demo[\"x_bucket_10\"] + rng.normal(0, 0.5, n)\n",
    "\n",
    "for c in [\"x_round_0p05\", \"x_bucket_10\", \"x_zero_spike\"]:\n",
    "    spiky_report(df_demo, c, topk=10, bins=60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f54a1641",
   "metadata": {},
   "source": [
    "## 2) 为什么“连续假设”会失效\n",
    "\n",
    "spiky 数值特征的风险点（可用于解释/写在结论页）：\n",
    "1. 变量并非真正连续，距离/梯度意义弱；线性/核方法容易做不合理插值  \n",
    "2. 分布强离散会导致残差模式异常（异方差、分段结构）  \n",
    "3. 取值重复率高时，编码（尤其 target encoding）在不恰当切分下容易“键值记忆”导致泄漏/过拟合  \n",
    "4. 树模型对阈值切分天然匹配此类变量，更稳健\n",
    "\n",
    "因此：优先把它当作 **类别/序数** 或交给 **树模型**；若使用 target encoding，必须严格 OOF（时序用 past-only）。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4579660b",
   "metadata": {},
   "source": [
    "## 3) 处理路线图（选择逻辑）\n",
    "\n",
    "把一个 spiky 数值特征 `x` 分成三类场景：\n",
    "\n",
    "### A. 取值很少（例如 nunique < 50）\n",
    "- 直接当作 categorical（OneHot）\n",
    "- 或明确有顺序含义时当作 ordinal（保留整数等级）\n",
    "\n",
    "### B. 取值中等偏多，但仍强离散（例如 50 ~ 5k）\n",
    "- OneHot 维度可能太大\n",
    "- 用 target encoding（OOF + smoothing）\n",
    "- 或保留为数值但切换为树模型\n",
    "\n",
    "### C. 取值非常多（接近连续）\n",
    "- 这通常已经不是 spike，而是连续噪声\n",
    "- 走常规数值处理即可（标准化、winsorize、对数等）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec8a214d",
   "metadata": {},
   "source": [
    "## 4) Target Encoding（OOF + smoothing）模板\n",
    "\n",
    "直接用全量 `y` 对每个取值算均值再编码会泄漏标签信息（重复率高时相当于“查表”）。  \n",
    "OOF 做法：对每一折，用其余折的统计量去编码当前折。\n",
    "\n",
    "平滑（smoothing）用于小样本取值，避免极端均值：  \n",
    "`enc(v) = (n_v*mean_v + alpha*global_mean) / (n_v + alpha)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc0392d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def target_encode_oof(x, y, n_splits=5, alpha=20.0, random_state=0):\n",
    "    \"\"\"\n",
    "    OOF target encoding with smoothing (regression).\n",
    "    x: categorical-like feature (can be numeric but spiky)\n",
    "    y: target\n",
    "    returns: encoded series aligned with x.index\n",
    "    \"\"\"\n",
    "    x = pd.Series(x)\n",
    "    y = pd.Series(y)\n",
    "    global_mean = y.mean()\n",
    "\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
    "    enc = pd.Series(index=x.index, dtype=float)\n",
    "\n",
    "    for tr_idx, va_idx in kf.split(x):\n",
    "        x_tr, y_tr = x.iloc[tr_idx], y.iloc[tr_idx]\n",
    "        stats = y_tr.groupby(x_tr).agg([\"mean\", \"count\"])\n",
    "        smooth = (stats[\"count\"] * stats[\"mean\"] + alpha * global_mean) / (stats[\"count\"] + alpha)\n",
    "        enc.iloc[va_idx] = x.iloc[va_idx].map(smooth).fillna(global_mean).astype(float)\n",
    "\n",
    "    return enc\n",
    "\n",
    "enc_demo = target_encode_oof(df_demo[\"x_bucket_10\"], df_demo[\"y_reg\"], n_splits=5, alpha=50.0)\n",
    "enc_demo.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac19a03a",
   "metadata": {},
   "source": [
    "## 5) 时间序列场景：past-only target encoding（避免未来信息）\n",
    "\n",
    "时间序列下 encoding 必须只使用“过去”：\n",
    "- 对每个时间点 t 的样本，只能用 < t 的数据估计映射  \n",
    "- 常用：expanding mean / rolling mean + smoothing\n",
    "\n",
    "下面是最简 past-only 实现（逐行更新）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd39d1f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "def target_encode_past_only(x, y, time, alpha=20.0):\n",
    "    \"\"\"\n",
    "    Past-only target encoding with smoothing (regression).\n",
    "    encoding at row i uses only rows with time < time_i.\n",
    "    \"\"\"\n",
    "    df = pd.DataFrame({\"x\": x, \"y\": y, \"t\": time}).sort_values(\"t\")\n",
    "    global_sum = 0.0\n",
    "    global_cnt = 0\n",
    "\n",
    "    sum_by = defaultdict(float)\n",
    "    cnt_by = defaultdict(int)\n",
    "\n",
    "    enc_sorted = np.empty(len(df), dtype=float)\n",
    "\n",
    "    for i, (xi, yi) in enumerate(zip(df[\"x\"].values, df[\"y\"].values)):\n",
    "        global_mean = (global_sum / global_cnt) if global_cnt > 0 else 0.0\n",
    "\n",
    "        c = cnt_by.get(xi, 0)\n",
    "        s = sum_by.get(xi, 0.0)\n",
    "        if c == 0:\n",
    "            enc_val = global_mean\n",
    "        else:\n",
    "            mean_v = s / c\n",
    "            enc_val = (c * mean_v + alpha * global_mean) / (c + alpha)\n",
    "\n",
    "        enc_sorted[i] = enc_val\n",
    "\n",
    "        global_sum += float(yi)\n",
    "        global_cnt += 1\n",
    "        sum_by[xi] += float(yi)\n",
    "        cnt_by[xi] += 1\n",
    "\n",
    "    enc = pd.Series(enc_sorted, index=df.index).sort_index()\n",
    "    return enc.reindex(pd.Index(x.index))\n",
    "\n",
    "df_demo_ts = df_demo.copy()\n",
    "df_demo_ts[\"t\"] = np.arange(len(df_demo_ts))\n",
    "\n",
    "enc_past = target_encode_past_only(df_demo_ts[\"x_bucket_10\"], df_demo_ts[\"y_reg\"], df_demo_ts[\"t\"], alpha=50.0)\n",
    "enc_past.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96700f3d",
   "metadata": {},
   "source": [
    "## 6) categorical / ordinal 处理模板 + baseline 对比\n",
    "\n",
    "树模型对 spiky 变量更稳健（阈值切分天然匹配离散台阶）。  \n",
    "线性模型若要吃这类变量，更安全的做法是 OneHot（categorical），而非强行当连续数值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "120eee76",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df_demo[[\"x_bucket_10\", \"x_round_0p05\", \"x_zero_spike\"]]\n",
    "y = df_demo[\"y_reg\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "cat_cols = [\"x_bucket_10\"]\n",
    "num_cols = [\"x_round_0p05\", \"x_zero_spike\"]\n",
    "\n",
    "pre = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), cat_cols),\n",
    "        (\"num\", \"passthrough\", num_cols),\n",
    "    ]\n",
    ")\n",
    "\n",
    "model_ridge = Pipeline([(\"pre\", pre), (\"model\", Ridge(alpha=1.0))])\n",
    "model_tree = HistGradientBoostingRegressor(random_state=0)\n",
    "\n",
    "model_ridge.fit(X_train, y_train)\n",
    "model_tree.fit(X_train, y_train)\n",
    "\n",
    "pred_r = model_ridge.predict(X_test)\n",
    "pred_t = model_tree.predict(X_test)\n",
    "\n",
    "rmse_r = mean_squared_error(y_test, pred_r, squared=False)\n",
    "rmse_t = mean_squared_error(y_test, pred_t, squared=False)\n",
    "\n",
    "print(\"RMSE (OneHot+Ridge):\", rmse_r)\n",
    "print(\"RMSE (Tree baseline):\", rmse_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa0638cd",
   "metadata": {},
   "source": [
    "## 7) Presentation \n",
    "\n",
    "- “`<feature>` is numeric but heavily discretized (spiky distribution), likely due to rounding/bucketing. Treating it as continuous may introduce misleading interpolation, so it’s handled as categorical/ordinal (and compared with OOF target encoding). Tree-based models are naturally robust here and serve as a strong baseline.”\n",
    "\n",
    "时间序列版本：\n",
    "- “To avoid leakage, any target encoding for `<feature>` uses past-only statistics (expanding/rolling) consistent with the time split.”"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eab21d0",
   "metadata": {},
   "source": [
    "## 8) 现场最小操作顺序（自检）\n",
    "\n",
    "1. `spiky_report(df, col)`：确认分布形态、取值规模、步长  \n",
    "2. `nunique` 很小：categorical / ordinal  \n",
    "3. `nunique` 中等且 OneHot 会爆：OOF target encoding（时序用 past-only）  \n",
    "4. baseline：树模型（GBDT/HistGB） vs 线性（Ridge/Lasso）  \n",
    "5. 汇报：强调“生成机制导致离散化”，并说明 encoding 如何避免泄漏"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8"
  },
  "title": "Spiky / Discretized Numeric Features Playbook"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
