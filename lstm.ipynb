{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8cc5c65b",
   "metadata": {},
   "source": [
    "# Dataset Interview — 时序建模 LSTM 训练与部署速查（可直接照抄）\n",
    "\n",
    "> 目标：在有限时间内完成 **数据读取 → 时间切分 → 特征/窗口 → 基线 → LSTM → 评估 → 结果导出 → 汇报要点** 的闭环。  \n",
    "> 写法：给自己看的操作手册，按顺序跑。  \n",
    "> 约束：时间序列严格防泄漏；所有 fit 只在 train 上做；val/test 只 transform。  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7490dcb",
   "metadata": {},
   "source": [
    "## 0. 全局配置（先定死）\n",
    "\n",
    "- 预测任务：单步 `horizon=1` 优先；多步之后再扩展。  \n",
    "- 输入窗口：`lookback` 从小到大（例如 30 → 60 → 120）逐步加。  \n",
    "- 验证方式：时间切分（walk-forward 若时间允许）。  \n",
    "- 产出：一个可复现的 `run_id`，保存 model、scaler、预测结果、图。  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f32e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== 0) 环境与随机种子 ====\n",
    "import os, time, json, math, random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "RUN_ID = time.strftime(\"%Y%m%d_%H%M%S\")\n",
    "ART_DIR = f\"artifacts_{RUN_ID}\"\n",
    "os.makedirs(ART_DIR, exist_ok=True)\n",
    "\n",
    "print(\"RUN_ID:\", RUN_ID)\n",
    "print(\"ART_DIR:\", ART_DIR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11a3fffa",
   "metadata": {},
   "source": [
    "## 1. 依赖导入（保持轻量）\n",
    "\n",
    "- tabular 基线：`sklearn`  \n",
    "- LSTM：`torch`（若环境无 torch，现场安装；若安装不顺，直接只交付基线）  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "813b4c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== 1) 依赖导入 ====\n",
    "from dataclasses import dataclass\n",
    "from typing import Optional, Tuple, Dict\n",
    "\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# 可选：如果 metric 是方向/分类，换 LogisticRegression / XGBoost(若允许) 等\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8befd3fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== 1b) Torch（可选）====\n",
    "TORCH_OK = True\n",
    "try:\n",
    "    import torch\n",
    "    import torch.nn as nn\n",
    "    from torch.utils.data import DataLoader, TensorDataset\n",
    "    print(\"torch:\", torch.__version__, \"| cuda:\", torch.cuda.is_available())\n",
    "except Exception as e:\n",
    "    TORCH_OK = False\n",
    "    print(\"Torch not available:\", repr(e))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b5a91c",
   "metadata": {},
   "source": [
    "## 2. 数据加载与基本检查\n",
    "\n",
    "### 假设输入数据至少包含：\n",
    "- 时间列：`timestamp`（或等价列名）  \n",
    "- 目标列：`y`（或等价列名）  \n",
    "- 特征列：若原始是面板数据（asset/region），先做筛选或分组后建模\n",
    "\n",
    "### 输出目标：\n",
    "- 一个按时间排序的 DataFrame：`df`  \n",
    "- 不允许乱序  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca6d5b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== 2) 数据加载（按现场数据改路径/列名）====\n",
    "DATA_PATH = \"data.csv\"  # TODO: 修改\n",
    "\n",
    "# 常见：csv/parquet\n",
    "# df = pd.read_csv(DATA_PATH)\n",
    "# df = pd.read_parquet(DATA_PATH)\n",
    "\n",
    "# 这里先放占位\n",
    "df = None\n",
    "print(\"Set DATA_PATH and load df\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e25ba18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== 2b) schema 约束检查（加载后解注释）====\n",
    "# assert df is not None\n",
    "# print(df.shape)\n",
    "# print(df.columns.tolist()[:50])\n",
    "# df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "473bcc32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== 2c) 列名对齐（加载后改这里）====\n",
    "# TIME_COL = \"timestamp\"\n",
    "# TARGET_COL = \"y\"\n",
    "# ID_COL = None  # 面板数据可设为 \"asset\" / \"region\" 等；单序列留 None\n",
    "# EXTRA_DROP_COLS = []\n",
    "\n",
    "# df[TIME_COL] = pd.to_datetime(df[TIME_COL])\n",
    "# df = df.sort_values([ID_COL, TIME_COL] if ID_COL else [TIME_COL]).reset_index(drop=True)\n",
    "\n",
    "# # 缺失基本情况\n",
    "# print(df.isna().mean().sort_values(ascending=False).head(20))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d64c39a4",
   "metadata": {},
   "source": [
    "## 3. 时间切分（防泄漏一票否决项）\n",
    "\n",
    "切分方式：\n",
    "- 单序列：按时间切 `train / val / test`  \n",
    "- 面板数据：先按 `ID_COL` 分组，各组内部按时间切；或先选一个 ID 做 demo，再扩展\n",
    "\n",
    "这里先实现：**单序列** 的最稳切分。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf956c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== 3) 单序列时间切分 ====\n",
    "@dataclass\n",
    "class SplitConfig:\n",
    "    train_frac: float = 0.7\n",
    "    val_frac: float = 0.15\n",
    "    # test_frac = 1 - train_frac - val_frac\n",
    "\n",
    "def time_split(df: pd.DataFrame, time_col: str, cfg: SplitConfig):\n",
    "    n = len(df)\n",
    "    i1 = int(n * cfg.train_frac)\n",
    "    i2 = int(n * (cfg.train_frac + cfg.val_frac))\n",
    "    train = df.iloc[:i1].copy()\n",
    "    val = df.iloc[i1:i2].copy()\n",
    "    test = df.iloc[i2:].copy()\n",
    "    return train, val, test\n",
    "\n",
    "# 用法：\n",
    "# train_df, val_df, test_df = time_split(df, TIME_COL, SplitConfig())\n",
    "# print(len(train_df), len(val_df), len(test_df))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c970cbda",
   "metadata": {},
   "source": [
    "## 4. 基础清洗与缺失处理（先做能跑的版本）\n",
    "\n",
    "原则：\n",
    "- 目标缺失：直接丢弃对应行（否则监督信号不干净）  \n",
    "- 特征缺失：先 `ffill/bfill`，剩余再 `fillna(0)`；同时保留缺失指示列（可选）  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a585f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== 4) 缺失处理（按现场数据改规则）====\n",
    "def basic_clean(df: pd.DataFrame, target_col: str, time_col: str):\n",
    "    df = df.copy()\n",
    "    # 目标缺失直接丢弃\n",
    "    df = df.dropna(subset=[target_col])\n",
    "    # 特征列集合\n",
    "    feat_cols = [c for c in df.columns if c not in [target_col, time_col]]\n",
    "    # 缺失指示列（可选）\n",
    "    for c in feat_cols:\n",
    "        if df[c].isna().any():\n",
    "            df[f\"{c}__isna\"] = df[c].isna().astype(np.int8)\n",
    "    # 简单填补\n",
    "    df[feat_cols] = df[feat_cols].ffill().bfill()\n",
    "    df[feat_cols] = df[feat_cols].fillna(0.0)\n",
    "    return df\n",
    "\n",
    "# 用法：\n",
    "# train_df = basic_clean(train_df, TARGET_COL, TIME_COL)\n",
    "# val_df   = basic_clean(val_df, TARGET_COL, TIME_COL)\n",
    "# test_df  = basic_clean(test_df, TARGET_COL, TIME_COL)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d79200db",
   "metadata": {},
   "source": [
    "## 5. 特征工程（tabular 基线用）\n",
    "\n",
    "最低配：\n",
    "- lag：`y_{t-1}, y_{t-2}, ...` 或对关键特征做 lag  \n",
    "- rolling：均值/方差/极值（rolling 前 shift(1)）  \n",
    "- 时间特征：小时/星期/月份（若有明显周期）  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a0d9e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== 5) lag/rolling 特征（单序列版本）====\n",
    "def add_lag_rolling_features(df: pd.DataFrame, time_col: str, target_col: str,\n",
    "                            lags=(1,2,3,5,10),\n",
    "                            windows=(5,10,20)):\n",
    "    df = df.copy()\n",
    "    df = df.sort_values(time_col).reset_index(drop=True)\n",
    "\n",
    "    # target lag\n",
    "    for k in lags:\n",
    "        df[f\"{target_col}_lag{k}\"] = df[target_col].shift(k)\n",
    "\n",
    "    # rolling on shifted target (防泄漏)\n",
    "    shifted = df[target_col].shift(1)\n",
    "    for w in windows:\n",
    "        df[f\"{target_col}_roll_mean{w}\"] = shifted.rolling(w).mean()\n",
    "        df[f\"{target_col}_roll_std{w}\"]  = shifted.rolling(w).std()\n",
    "        df[f\"{target_col}_roll_min{w}\"]  = shifted.rolling(w).min()\n",
    "        df[f\"{target_col}_roll_max{w}\"]  = shifted.rolling(w).max()\n",
    "\n",
    "    # 时间特征（若 time_col 为 datetime）\n",
    "    if np.issubdtype(df[time_col].dtype, np.datetime64):\n",
    "        df[\"hour\"] = df[time_col].dt.hour.astype(np.int16)\n",
    "        df[\"dow\"]  = df[time_col].dt.dayofweek.astype(np.int16)\n",
    "        df[\"month\"]= df[time_col].dt.month.astype(np.int16)\n",
    "\n",
    "    return df\n",
    "\n",
    "# 用法：\n",
    "# train_df = add_lag_rolling_features(train_df, TIME_COL, TARGET_COL)\n",
    "# val_df   = add_lag_rolling_features(val_df, TIME_COL, TARGET_COL)\n",
    "# test_df  = add_lag_rolling_features(test_df, TIME_COL, TARGET_COL)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59b2f90f",
   "metadata": {},
   "source": [
    "## 6. tabular 基线训练（先拿分）\n",
    "\n",
    "流程：\n",
    "1) 选特征列  \n",
    "2) scaler：只 fit train  \n",
    "3) 模型：Ridge 先跑；再试 RandomForest（时间允许再调参）  \n",
    "4) 输出 val 指标、画预测曲线  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b18fbb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== 6) 取特征 + 对齐列 ====\n",
    "def get_feature_columns(df: pd.DataFrame, time_col: str, target_col: str):\n",
    "    drop = {time_col, target_col}\n",
    "    return [c for c in df.columns if c not in drop]\n",
    "\n",
    "def align_columns(train_df, val_df, test_df, feat_cols):\n",
    "    # 缺列补 0，多列忽略\n",
    "    def _align(d):\n",
    "        d = d.copy()\n",
    "        for c in feat_cols:\n",
    "            if c not in d.columns:\n",
    "                d[c] = 0.0\n",
    "        return d[feat_cols]\n",
    "    return _align(train_df), _align(val_df), _align(test_df)\n",
    "\n",
    "def drop_na_rows(df: pd.DataFrame, cols):\n",
    "    return df.dropna(subset=cols)\n",
    "\n",
    "# 用法：\n",
    "# feat_cols = get_feature_columns(train_df, TIME_COL, TARGET_COL)\n",
    "# train_df2 = drop_na_rows(train_df, feat_cols + [TARGET_COL])\n",
    "# val_df2   = drop_na_rows(val_df, feat_cols + [TARGET_COL])\n",
    "# test_df2  = drop_na_rows(test_df, feat_cols + [TARGET_COL])\n",
    "\n",
    "# Xtr, Xva, Xte = align_columns(train_df2, val_df2, test_df2, feat_cols)\n",
    "# ytr, yva, yte = train_df2[TARGET_COL].values, val_df2[TARGET_COL].values, test_df2[TARGET_COL].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ee2a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== 6b) 基线模型训练与评估 ====\n",
    "def eval_regression(y_true, y_pred, prefix=\"\"):\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    rmse = math.sqrt(mse)\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    out = {\"mse\": mse, \"rmse\": rmse, \"mae\": mae, \"r2\": r2}\n",
    "    print(prefix, json.dumps(out, ensure_ascii=False))\n",
    "    return out\n",
    "\n",
    "# 用法：\n",
    "# scaler = RobustScaler()  # heavy-tail 常见，先用 robust\n",
    "# Xtr_s = scaler.fit_transform(Xtr)\n",
    "# Xva_s = scaler.transform(Xva)\n",
    "# Xte_s = scaler.transform(Xte)\n",
    "\n",
    "# ridge = Ridge(alpha=1.0, random_state=SEED)\n",
    "# ridge.fit(Xtr_s, ytr)\n",
    "# pva = ridge.predict(Xva_s)\n",
    "# pte = ridge.predict(Xte_s)\n",
    "\n",
    "# val_metrics = eval_regression(yva, pva, \"Ridge val:\")\n",
    "# test_metrics= eval_regression(yte, pte, \"Ridge test:\")\n",
    "\n",
    "# # 保存\n",
    "# import joblib\n",
    "# joblib.dump(scaler, f\"{ART_DIR}/scaler.joblib\")\n",
    "# joblib.dump(ridge,  f\"{ART_DIR}/ridge.joblib\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc7d917a",
   "metadata": {},
   "source": [
    "## 7. LSTM 输入窗口构造（核心）\n",
    "\n",
    "定义：用过去 `lookback` 步的特征序列预测 `t+horizon-1`。  \n",
    "输入形状：`(N, lookback, n_features)`  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b9bade7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== 7) make windows ====\n",
    "def make_windows(X: np.ndarray, y: np.ndarray, lookback: int = 60, horizon: int = 1, stride: int = 1):\n",
    "    X = np.asarray(X)\n",
    "    y = np.asarray(y)\n",
    "    T = len(X)\n",
    "    Xw, yw = [], []\n",
    "    end = T - horizon + 1\n",
    "    for t in range(lookback, end, stride):\n",
    "        Xw.append(X[t - lookback:t])\n",
    "        yw.append(y[t + horizon - 1])\n",
    "    return np.stack(Xw), np.asarray(yw)\n",
    "\n",
    "# 用法：\n",
    "# LOOKBACK = 60\n",
    "# HORIZON = 1\n",
    "# Xtr_w, ytr_w = make_windows(Xtr_s, ytr, lookback=LOOKBACK, horizon=HORIZON)\n",
    "# Xva_w, yva_w = make_windows(Xva_s, yva, lookback=LOOKBACK, horizon=HORIZON)\n",
    "# Xte_w, yte_w = make_windows(Xte_s, yte, lookback=LOOKBACK, horizon=HORIZON)\n",
    "# print(Xtr_w.shape, ytr_w.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59a398cd",
   "metadata": {},
   "source": [
    "## 8. LSTM 模型与训练循环（PyTorch 最小实现）\n",
    "\n",
    "- 结构：LSTM → 取最后一步 hidden → linear head  \n",
    "- 训练：Adam + MSE + early stopping + 梯度裁剪  \n",
    "- 保存：best state_dict  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae4ce68d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== 8) LSTM 回归模型 ====\n",
    "if TORCH_OK:\n",
    "    class LSTMReg(nn.Module):\n",
    "        def __init__(self, n_features: int, hidden: int = 64, num_layers: int = 1, dropout: float = 0.0):\n",
    "            super().__init__()\n",
    "            self.lstm = nn.LSTM(\n",
    "                input_size=n_features,\n",
    "                hidden_size=hidden,\n",
    "                num_layers=num_layers,\n",
    "                batch_first=True,\n",
    "                dropout=dropout if num_layers > 1 else 0.0\n",
    "            )\n",
    "            self.head = nn.Linear(hidden, 1)\n",
    "\n",
    "        def forward(self, x):\n",
    "            out, _ = self.lstm(x)      # (B, L, H)\n",
    "            last = out[:, -1, :]       # (B, H)\n",
    "            yhat = self.head(last).squeeze(-1)  # (B,)\n",
    "            return yhat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc0f9d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== 8b) 训练器 ====\n",
    "if TORCH_OK:\n",
    "    def train_lstm(Xtr_w, ytr_w, Xva_w, yva_w,\n",
    "                   hidden=64, num_layers=1, dropout=0.0,\n",
    "                   lr=1e-3, batch=256, epochs=30, patience=3,\n",
    "                   device=None):\n",
    "        device = device or (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "        Xtr_t = torch.tensor(Xtr_w, dtype=torch.float32)\n",
    "        ytr_t = torch.tensor(ytr_w, dtype=torch.float32)\n",
    "        Xva_t = torch.tensor(Xva_w, dtype=torch.float32)\n",
    "        yva_t = torch.tensor(yva_w, dtype=torch.float32)\n",
    "\n",
    "        dl = DataLoader(TensorDataset(Xtr_t, ytr_t), batch_size=batch, shuffle=False)\n",
    "\n",
    "        model = LSTMReg(n_features=Xtr_w.shape[-1], hidden=hidden, num_layers=num_layers, dropout=dropout).to(device)\n",
    "        opt = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "        loss_fn = nn.MSELoss()\n",
    "\n",
    "        best_loss = float(\"inf\")\n",
    "        best_state = None\n",
    "        bad = 0\n",
    "\n",
    "        for ep in range(1, epochs + 1):\n",
    "            model.train()\n",
    "            for xb, yb in dl:\n",
    "                xb = xb.to(device); yb = yb.to(device)\n",
    "                opt.zero_grad()\n",
    "                pred = model(xb)\n",
    "                loss = loss_fn(pred, yb)\n",
    "                loss.backward()\n",
    "                nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "                opt.step()\n",
    "\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                vpred = model(Xva_t.to(device))\n",
    "                vloss = loss_fn(vpred, yva_t.to(device)).item()\n",
    "\n",
    "            print(f\"ep={ep:02d} val_mse={vloss:.6f}\")\n",
    "\n",
    "            if vloss < best_loss - 1e-6:\n",
    "                best_loss = vloss\n",
    "                best_state = {k: v.detach().cpu().clone() for k, v in model.state_dict().items()}\n",
    "                bad = 0\n",
    "            else:\n",
    "                bad += 1\n",
    "                if bad >= patience:\n",
    "                    break\n",
    "\n",
    "        if best_state is not None:\n",
    "            model.load_state_dict(best_state)\n",
    "        return model, best_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58abe187",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== 8c) 推理与保存 ====\n",
    "if TORCH_OK:\n",
    "    def predict_lstm(model, Xw, device=None, batch=512):\n",
    "        device = device or (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        model.eval()\n",
    "        X_t = torch.tensor(Xw, dtype=torch.float32)\n",
    "        dl = DataLoader(TensorDataset(X_t), batch_size=batch, shuffle=False)\n",
    "        out = []\n",
    "        with torch.no_grad():\n",
    "            for (xb,) in dl:\n",
    "                xb = xb.to(device)\n",
    "                pred = model(xb).detach().cpu().numpy()\n",
    "                out.append(pred)\n",
    "        return np.concatenate(out, axis=0)\n",
    "\n",
    "    # 用法：\n",
    "    # model, best = train_lstm(Xtr_w, ytr_w, Xva_w, yva_w)\n",
    "    # pva = predict_lstm(model, Xva_w)\n",
    "    # pte = predict_lstm(model, Xte_w)\n",
    "    # eval_regression(yva_w, pva, \"LSTM val:\")\n",
    "    # eval_regression(yte_w, pte, \"LSTM test:\")\n",
    "    #\n",
    "    # torch.save(model.state_dict(), f\"{ART_DIR}/lstm_state.pt\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adfcbaec",
   "metadata": {},
   "source": [
    "## 9. 可视化（如果允许 matplotlib）\n",
    "\n",
    "输出两张图：\n",
    "1) val/test 的真实 vs 预测（时间轴对齐）  \n",
    "2) 残差分布/绝对误差随时间变化（可选）  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f92153",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== 9) 画图（可选）====\n",
    "PLOT_OK = True\n",
    "try:\n",
    "    import matplotlib.pyplot as plt\n",
    "except Exception as e:\n",
    "    PLOT_OK = False\n",
    "    print(\"matplotlib not available:\", repr(e))\n",
    "\n",
    "def plot_series(y_true, y_pred, title, path):\n",
    "    if not PLOT_OK:\n",
    "        return\n",
    "    plt.figure()\n",
    "    plt.plot(y_true)\n",
    "    plt.plot(y_pred)\n",
    "    plt.title(title)\n",
    "    plt.legend([\"true\", \"pred\"])\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(path, dpi=150)\n",
    "    plt.close()\n",
    "\n",
    "# 用法：\n",
    "# plot_series(yva_w, pva, \"LSTM val true vs pred\", f\"{ART_DIR}/lstm_val.png\")\n",
    "# plot_series(yte_w, pte, \"LSTM test true vs pred\", f\"{ART_DIR}/lstm_test.png\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6257b126",
   "metadata": {},
   "source": [
    "## 10. 汇报模板（直接照念的要点）\n",
    "\n",
    "- 数据：时间范围、缺失比例、是否有面板维度  \n",
    "- 切分：train/val/test 的时间边界（具体日期/索引），强调无泄漏  \n",
    "- 基线：Ridge / RF 指标（val/test），解释优势：快、稳、可解释  \n",
    "- LSTM：输入窗口 lookback、特征维度、训练轮数、early stopping，指标对比基线  \n",
    "- 误差分析：在哪些时间段偏差大（高波动/极端值/缺失集中）  \n",
    "- 下一步：多步预测、walk-forward CV、改 loss（Huber/Quantile）、加入外生变量/节假日特征  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e662973",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== 10) 自动生成汇报摘要（把关键数字写到 json）====\n",
    "def save_summary(path, **kwargs):\n",
    "    with open(path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(kwargs, f, ensure_ascii=False, indent=2)\n",
    "    print(\"Saved:\", path)\n",
    "\n",
    "# 用法：\n",
    "# save_summary(\n",
    "#     f\"{ART_DIR}/summary.json\",\n",
    "#     run_id=RUN_ID,\n",
    "#     lookback=LOOKBACK,\n",
    "#     horizon=HORIZON,\n",
    "#     baseline_val=val_metrics,\n",
    "#     baseline_test=test_metrics,\n",
    "#     lstm_val=lstm_val_metrics,\n",
    "#     lstm_test=lstm_test_metrics,\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df86196",
   "metadata": {},
   "source": [
    "## 11. 快速故障排查（只列结论）\n",
    "\n",
    "- 训练不收敛：lookback 降小、hidden 降小、lr 降到 3e-4、检查 scaler 与窗口对齐  \n",
    "- val 很好 test 很差：存在非平稳/分布漂移；改 robust 特征、加 drift-aware split、减少过拟合  \n",
    "- LSTM 不如基线：特征已足够；LSTM 只在明显非线性/长依赖时占优；用它当加分项即可  \n",
    "- 时间不够：只交付基线 + 完整评估 + 清晰汇报逻辑  \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.x"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
