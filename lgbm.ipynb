{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24838624",
   "metadata": {},
   "source": [
    "# Dataset Interview：LightGBM 现场训练与交付 Notebook\n",
    "\n",
    "> 目标：在受限环境中快速完成 **数据检查 → 切分 → 训练 → 评估 → 解释 → 导出**，并保留可复现的运行痕迹。  \n",
    "> 时间：2026-01-29  \n",
    "> 约定：全程使用固定随机种子；时间序列任务默认按时间切分；所有输出写入 `./artifacts/`。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df813d8c",
   "metadata": {},
   "source": [
    "## 0. 运行环境与目录结构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2964a86f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os, sys, json, math, time, random\n",
    "from pathlib import Path\n",
    "\n",
    "ART = Path(\"./artifacts\")\n",
    "ART.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"Python:\", sys.version.split()[0])\n",
    "print(\"CWD:\", Path(\".\").resolve())\n",
    "print(\"Artifacts dir:\", ART.resolve())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d2ce819",
   "metadata": {},
   "source": [
    "## 1. 依赖导入（含备胎模型）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a06c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import TimeSeriesSplit, KFold\n",
    "from sklearn.metrics import (\n",
    "    mean_squared_error, mean_absolute_error,\n",
    "    roc_auc_score, average_precision_score, log_loss,\n",
    "    accuracy_score, f1_score\n",
    ")\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# 备胎：LightGBM 不可用时仍能给出强 baseline\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor, HistGradientBoostingClassifier\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "random.seed(RANDOM_SEED)\n",
    "\n",
    "# LightGBM（若不可用，后续会自动切换到备胎）\n",
    "LGBM_OK = True\n",
    "try:\n",
    "    import lightgbm as lgb\n",
    "    from lightgbm import LGBMRegressor, LGBMClassifier\n",
    "    print(\"LightGBM:\", lgb.__version__)\n",
    "except Exception as e:\n",
    "    LGBM_OK = False\n",
    "    print(\"LightGBM import failed -> fallback to sklearn HGB. Error:\", repr(e))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da2294f6",
   "metadata": {},
   "source": [
    "## 2. 全局配置（按任务修改）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2646a214",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "CFG = {\n",
    "    # === 必填 ===\n",
    "    \"data_path\": \"./data/train.csv\",   # 或 parquet / feather\n",
    "    \"target\": \"y\",\n",
    "    \"time_col\": None,                 # 时间列名（时间序列任务填写）\n",
    "    \"group_col\": None,                # 实体列名（如 symbol/user_id；可选）\n",
    "    \"task\": \"binary\",                 # {\"reg\", \"binary\", \"multiclass\"}\n",
    "\n",
    "    # === 切分 ===\n",
    "    \"test_size\": 0.2,                 # 时间序列：按最后 test_size 比例做验证\n",
    "    \"n_splits\": 5,                    # CV 折数（时间序列用 TimeSeriesSplit）\n",
    "\n",
    "    # === 类别特征处理 ===\n",
    "    \"cat_cols\": [],                   # 手动指定类别列（推荐）\n",
    "\n",
    "    # === 训练 ===\n",
    "    \"metric\": None,                   # None -> 自动按 task 选择\n",
    "    \"early_stopping_rounds\": 200,\n",
    "    \"n_estimators\": 5000,\n",
    "    \"learning_rate\": 0.03,\n",
    "    \"num_leaves\": 63,\n",
    "    \"min_child_samples\": 50,\n",
    "    \"subsample\": 0.8,\n",
    "    \"colsample_bytree\": 0.8,\n",
    "    \"reg_alpha\": 0.0,\n",
    "    \"reg_lambda\": 1.0,\n",
    "}\n",
    "CFG\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afbd1742",
   "metadata": {},
   "source": [
    "## 3. 数据读取（CSV/Parquet 自适应）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4fd7bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def read_any(path: str) -> pd.DataFrame:\n",
    "    p = Path(path)\n",
    "    if not p.exists():\n",
    "        raise FileNotFoundError(f\"File not found: {p.resolve()}\")\n",
    "    if p.suffix.lower() in [\".csv\"]:\n",
    "        return pd.read_csv(p)\n",
    "    if p.suffix.lower() in [\".parquet\"]:\n",
    "        return pd.read_parquet(p)\n",
    "    if p.suffix.lower() in [\".feather\"]:\n",
    "        return pd.read_feather(p)\n",
    "    raise ValueError(f\"Unsupported file type: {p.suffix}\")\n",
    "\n",
    "df = read_any(CFG[\"data_path\"])\n",
    "print(\"shape:\", df.shape)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d40484",
   "metadata": {},
   "source": [
    "## 4. 快速体检（缺失/重复/目标分布/时间覆盖）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de7205c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def quick_profile(df: pd.DataFrame, target: str, time_col: str | None):\n",
    "    out = {}\n",
    "    out[\"n_rows\"] = len(df)\n",
    "    out[\"n_cols\"] = df.shape[1]\n",
    "    out[\"dup_rows\"] = int(df.duplicated().sum())\n",
    "    out[\"missing_top10\"] = df.isna().mean().sort_values(ascending=False).head(10).to_dict()\n",
    "    if target in df.columns:\n",
    "        y = df[target]\n",
    "        out[\"target_missing\"] = float(y.isna().mean())\n",
    "        out[\"target_unique\"] = int(y.nunique(dropna=True))\n",
    "        if pd.api.types.is_numeric_dtype(y):\n",
    "            out[\"target_desc\"] = y.describe().to_dict()\n",
    "        else:\n",
    "            out[\"target_vc\"] = y.value_counts(dropna=False).head(20).to_dict()\n",
    "    if time_col and time_col in df.columns:\n",
    "        t = pd.to_datetime(df[time_col], errors=\"coerce\")\n",
    "        out[\"time_missing\"] = float(t.isna().mean())\n",
    "        out[\"time_min\"] = None if t.isna().all() else str(t.min())\n",
    "        out[\"time_max\"] = None if t.isna().all() else str(t.max())\n",
    "    return out\n",
    "\n",
    "profile = quick_profile(df, CFG[\"target\"], CFG[\"time_col\"])\n",
    "profile\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f6ff7a1",
   "metadata": {},
   "source": [
    "## 5. 切分（时间序列：按时间排序 + 最后区间验证）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "454f4fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_valid_split(df: pd.DataFrame, cfg: dict):\n",
    "    target = cfg[\"target\"]\n",
    "    time_col = cfg[\"time_col\"]\n",
    "    test_size = cfg[\"test_size\"]\n",
    "    if time_col and time_col in df.columns:\n",
    "        d = df.copy()\n",
    "        d[time_col] = pd.to_datetime(d[time_col], errors=\"coerce\")\n",
    "        d = d.sort_values(time_col).reset_index(drop=True)\n",
    "        cut = int(len(d) * (1 - test_size))\n",
    "        train_df = d.iloc[:cut].copy()\n",
    "        valid_df = d.iloc[cut:].copy()\n",
    "        return train_df, valid_df\n",
    "    else:\n",
    "        # 非时序：默认末尾切（保持可复现，不 shuffle）\n",
    "        cut = int(len(df) * (1 - test_size))\n",
    "        train_df = df.iloc[:cut].copy()\n",
    "        valid_df = df.iloc[cut:].copy()\n",
    "        return train_df, valid_df\n",
    "\n",
    "train_df, valid_df = train_valid_split(df, CFG)\n",
    "print(\"train:\", train_df.shape, \"valid:\", valid_df.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "942ab47a",
   "metadata": {},
   "source": [
    "## 6. 特征列选择 + 类别列处理（pandas category）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3169737",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "TARGET = CFG[\"target\"]\n",
    "TIME_COL = CFG[\"time_col\"]\n",
    "GROUP_COL = CFG[\"group_col\"]\n",
    "\n",
    "drop_cols = [c for c in [TARGET, TIME_COL] if c and c in df.columns]\n",
    "X_cols = [c for c in df.columns if c not in drop_cols]\n",
    "\n",
    "# cat cols：按 CFG 或自动识别 object/string\n",
    "cat_cols = list(CFG[\"cat_cols\"])\n",
    "if not cat_cols:\n",
    "    cat_cols = [c for c in X_cols if df[c].dtype == \"object\"]\n",
    "num_cols = [c for c in X_cols if c not in cat_cols]\n",
    "\n",
    "def enforce_categories(d: pd.DataFrame, cat_cols: list[str]) -> pd.DataFrame:\n",
    "    d = d.copy()\n",
    "    for c in cat_cols:\n",
    "        if c in d.columns:\n",
    "            # 先转 string 再 category，减少混合类型坑\n",
    "            d[c] = d[c].astype(\"string\").fillna(\"<<MISSING>>\").astype(\"category\")\n",
    "    return d\n",
    "\n",
    "X_train = enforce_categories(train_df[X_cols], cat_cols)\n",
    "X_valid = enforce_categories(valid_df[X_cols], cat_cols)\n",
    "y_train = train_df[TARGET]\n",
    "y_valid = valid_df[TARGET]\n",
    "\n",
    "print(\"n_features:\", len(X_cols))\n",
    "print(\"cat:\", len(cat_cols), \"num:\", len(num_cols))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c91a61d7",
   "metadata": {},
   "source": [
    "## 7. 评价指标与统一打分函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb90e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_default_metric(task: str) -> str:\n",
    "    if task == \"reg\":\n",
    "        return \"rmse\"\n",
    "    if task == \"binary\":\n",
    "        return \"auc\"\n",
    "    if task == \"multiclass\":\n",
    "        return \"multi_logloss\"\n",
    "    raise ValueError(task)\n",
    "\n",
    "METRIC = CFG[\"metric\"] or get_default_metric(CFG[\"task\"])\n",
    "\n",
    "def score(task: str, y_true, y_pred, y_proba=None):\n",
    "    if task == \"reg\":\n",
    "        rmse = mean_squared_error(y_true, y_pred, squared=False)\n",
    "        mae = mean_absolute_error(y_true, y_pred)\n",
    "        return {\"rmse\": float(rmse), \"mae\": float(mae)}\n",
    "    if task == \"binary\":\n",
    "        out = {}\n",
    "        if y_proba is not None:\n",
    "            out[\"auc\"] = float(roc_auc_score(y_true, y_proba))\n",
    "            out[\"ap\"] = float(average_precision_score(y_true, y_proba))\n",
    "            out[\"logloss\"] = float(log_loss(y_true, y_proba, eps=1e-15))\n",
    "        out[\"acc\"] = float(accuracy_score(y_true, (y_pred > 0.5).astype(int) if y_proba is None else (y_proba >= 0.5).astype(int)))\n",
    "        out[\"f1\"] = float(f1_score(y_true, (y_pred > 0.5).astype(int) if y_proba is None else (y_proba >= 0.5).astype(int)))\n",
    "        return out\n",
    "    if task == \"multiclass\":\n",
    "        # y_proba: (n, K)\n",
    "        ll = float(log_loss(y_true, y_proba))\n",
    "        pred = np.argmax(y_proba, axis=1)\n",
    "        acc = float(accuracy_score(y_true, pred))\n",
    "        return {\"multi_logloss\": ll, \"acc\": acc}\n",
    "    raise ValueError(task)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9196d49d",
   "metadata": {},
   "source": [
    "## 8. 模型训练（LightGBM 优先；失败则备胎）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83eea47d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_model(cfg: dict, X_train, y_train, X_valid, y_valid, cat_cols: list[str]):\n",
    "    task = cfg[\"task\"]\n",
    "    esr = cfg[\"early_stopping_rounds\"]\n",
    "\n",
    "    if LGBM_OK:\n",
    "        if task == \"reg\":\n",
    "            model = LGBMRegressor(\n",
    "                n_estimators=cfg[\"n_estimators\"],\n",
    "                learning_rate=cfg[\"learning_rate\"],\n",
    "                num_leaves=cfg[\"num_leaves\"],\n",
    "                min_child_samples=cfg[\"min_child_samples\"],\n",
    "                subsample=cfg[\"subsample\"],\n",
    "                colsample_bytree=cfg[\"colsample_bytree\"],\n",
    "                reg_alpha=cfg[\"reg_alpha\"],\n",
    "                reg_lambda=cfg[\"reg_lambda\"],\n",
    "                random_state=RANDOM_SEED,\n",
    "                n_jobs=-1,\n",
    "            )\n",
    "            model.fit(\n",
    "                X_train, y_train,\n",
    "                eval_set=[(X_valid, y_valid)],\n",
    "                eval_metric=cfg[\"metric\"] or \"rmse\",\n",
    "                categorical_feature=cat_cols if len(cat_cols) else \"auto\",\n",
    "                callbacks=[\n",
    "                    lgb.early_stopping(esr, verbose=False),\n",
    "                    lgb.log_evaluation(200),\n",
    "                ],\n",
    "            )\n",
    "            return model, \"lgbm\"\n",
    "\n",
    "        if task == \"binary\":\n",
    "            model = LGBMClassifier(\n",
    "                n_estimators=cfg[\"n_estimators\"],\n",
    "                learning_rate=cfg[\"learning_rate\"],\n",
    "                num_leaves=cfg[\"num_leaves\"],\n",
    "                min_child_samples=cfg[\"min_child_samples\"],\n",
    "                subsample=cfg[\"subsample\"],\n",
    "                colsample_bytree=cfg[\"colsample_bytree\"],\n",
    "                reg_alpha=cfg[\"reg_alpha\"],\n",
    "                reg_lambda=cfg[\"reg_lambda\"],\n",
    "                random_state=RANDOM_SEED,\n",
    "                n_jobs=-1,\n",
    "            )\n",
    "            model.fit(\n",
    "                X_train, y_train,\n",
    "                eval_set=[(X_valid, y_valid)],\n",
    "                eval_metric=cfg[\"metric\"] or \"auc\",\n",
    "                categorical_feature=cat_cols if len(cat_cols) else \"auto\",\n",
    "                callbacks=[\n",
    "                    lgb.early_stopping(esr, verbose=False),\n",
    "                    lgb.log_evaluation(200),\n",
    "                ],\n",
    "            )\n",
    "            return model, \"lgbm\"\n",
    "\n",
    "        if task == \"multiclass\":\n",
    "            n_classes = int(pd.Series(y_train).nunique())\n",
    "            model = LGBMClassifier(\n",
    "                objective=\"multiclass\",\n",
    "                num_class=n_classes,\n",
    "                n_estimators=cfg[\"n_estimators\"],\n",
    "                learning_rate=cfg[\"learning_rate\"],\n",
    "                num_leaves=cfg[\"num_leaves\"],\n",
    "                min_child_samples=cfg[\"min_child_samples\"],\n",
    "                subsample=cfg[\"subsample\"],\n",
    "                colsample_bytree=cfg[\"colsample_bytree\"],\n",
    "                reg_alpha=cfg[\"reg_alpha\"],\n",
    "                reg_lambda=cfg[\"reg_lambda\"],\n",
    "                random_state=RANDOM_SEED,\n",
    "                n_jobs=-1,\n",
    "            )\n",
    "            model.fit(\n",
    "                X_train, y_train,\n",
    "                eval_set=[(X_valid, y_valid)],\n",
    "                eval_metric=cfg[\"metric\"] or \"multi_logloss\",\n",
    "                categorical_feature=cat_cols if len(cat_cols) else \"auto\",\n",
    "                callbacks=[\n",
    "                    lgb.early_stopping(esr, verbose=False),\n",
    "                    lgb.log_evaluation(200),\n",
    "                ],\n",
    "            )\n",
    "            return model, \"lgbm\"\n",
    "\n",
    "    # 备胎：sklearn HGB（需要数值矩阵；类别做 one-hot）\n",
    "    pre = ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"cat\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False), cat_cols),\n",
    "            (\"num\", \"passthrough\", [c for c in X_train.columns if c not in cat_cols]),\n",
    "        ],\n",
    "        remainder=\"drop\",\n",
    "        verbose_feature_names_out=False,\n",
    "    )\n",
    "\n",
    "    if task == \"reg\":\n",
    "        model = HistGradientBoostingRegressor(random_state=RANDOM_SEED)\n",
    "        pipe = Pipeline([(\"pre\", pre), (\"model\", model)])\n",
    "        pipe.fit(X_train, y_train)\n",
    "        return pipe, \"hgb\"\n",
    "    if task == \"binary\":\n",
    "        model = HistGradientBoostingClassifier(random_state=RANDOM_SEED)\n",
    "        pipe = Pipeline([(\"pre\", pre), (\"model\", model)])\n",
    "        pipe.fit(X_train, y_train)\n",
    "        return pipe, \"hgb\"\n",
    "    if task == \"multiclass\":\n",
    "        model = HistGradientBoostingClassifier(random_state=RANDOM_SEED)\n",
    "        pipe = Pipeline([(\"pre\", pre), (\"model\", model)])\n",
    "        pipe.fit(X_train, y_train)\n",
    "        return pipe, \"hgb\"\n",
    "    raise ValueError(task)\n",
    "\n",
    "model, backend = train_model(CFG, X_train, y_train, X_valid, y_valid, cat_cols)\n",
    "print(\"backend:\", backend, \"model:\", type(model))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54913362",
   "metadata": {},
   "source": [
    "## 9. 验证集评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd2857e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "task = CFG[\"task\"]\n",
    "\n",
    "if task == \"reg\":\n",
    "    yhat = model.predict(X_valid)\n",
    "    metrics = score(task, y_valid, yhat)\n",
    "elif task == \"binary\":\n",
    "    if backend == \"lgbm\":\n",
    "        proba = model.predict_proba(X_valid)[:, 1]\n",
    "        yhat = proba\n",
    "        metrics = score(task, y_valid, y_pred=None, y_proba=proba)\n",
    "    else:\n",
    "        proba = model.predict_proba(X_valid)[:, 1]\n",
    "        metrics = score(task, y_valid, y_pred=None, y_proba=proba)\n",
    "elif task == \"multiclass\":\n",
    "    proba = model.predict_proba(X_valid)\n",
    "    metrics = score(task, y_valid, y_pred=None, y_proba=proba)\n",
    "else:\n",
    "    raise ValueError(task)\n",
    "\n",
    "metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdb363f3",
   "metadata": {},
   "source": [
    "## 10. 特征重要性（仅 LightGBM）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b5303ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "if backend == \"lgbm\":\n",
    "    imp = pd.DataFrame({\n",
    "        \"feature\": X_train.columns,\n",
    "        \"importance\": model.feature_importances_,\n",
    "    }).sort_values(\"importance\", ascending=False)\n",
    "    display(imp.head(30))\n",
    "    imp.to_csv(ART / \"feature_importance.csv\", index=False)\n",
    "    print(\"saved:\", ART / \"feature_importance.csv\")\n",
    "else:\n",
    "    print(\"非 LightGBM 后端：importance 使用 permutation_importance 或 SHAP（若环境允许）\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89bc128f",
   "metadata": {},
   "source": [
    "## 11. 误差分析（按时间/分组切片）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce293893",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def add_preds(df_part: pd.DataFrame, X_part, task: str, model, backend: str):\n",
    "    d = df_part.copy()\n",
    "    if task == \"reg\":\n",
    "        d[\"_pred\"] = model.predict(X_part)\n",
    "    elif task == \"binary\":\n",
    "        if hasattr(model, \"predict_proba\"):\n",
    "            d[\"_pred\"] = model.predict_proba(X_part)[:, 1]\n",
    "        else:\n",
    "            d[\"_pred\"] = model.predict(X_part)\n",
    "    else:\n",
    "        # 多分类：存最大类概率\n",
    "        d[\"_pred\"] = model.predict_proba(X_part).max(axis=1)\n",
    "    return d\n",
    "\n",
    "valid_with_pred = add_preds(valid_df, X_valid, CFG[\"task\"], model, backend)\n",
    "\n",
    "# 按时间分桶（若有时间列）\n",
    "if TIME_COL and TIME_COL in valid_with_pred.columns:\n",
    "    t = pd.to_datetime(valid_with_pred[TIME_COL], errors=\"coerce\")\n",
    "    valid_with_pred[\"_tbin\"] = pd.cut(t.view(\"int64\"), bins=10, duplicates=\"drop\")\n",
    "    print(valid_with_pred.groupby(\"_tbin\")[\"_pred\"].agg([\"count\",\"mean\"]).head())\n",
    "\n",
    "# 按 group 聚合（若有 group 列）\n",
    "if GROUP_COL and GROUP_COL in valid_with_pred.columns:\n",
    "    g = valid_with_pred.groupby(GROUP_COL)[\"_pred\"].agg([\"count\",\"mean\"]).sort_values(\"count\", ascending=False).head(20)\n",
    "    display(g)\n",
    "\n",
    "valid_with_pred.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d14653cb",
   "metadata": {},
   "source": [
    "## 12. 保存模型与配置（交付用）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7139c329",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import joblib\n",
    "\n",
    "joblib.dump(model, ART / \"model.pkl\")\n",
    "with open(ART / \"config.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(CFG, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(\"saved:\", ART / \"model.pkl\")\n",
    "print(\"saved:\", ART / \"config.json\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ea58d29",
   "metadata": {},
   "source": [
    "## 13. 单次推理模板（读取模型 + 生成预测）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e0626e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# new_df = read_any(\"./data/test.csv\")\n",
    "# new_X = enforce_categories(new_df[X_cols], cat_cols)\n",
    "\n",
    "# loaded = joblib.load(ART / \"model.pkl\")\n",
    "# if CFG[\"task\"] == \"reg\":\n",
    "#     pred = loaded.predict(new_X)\n",
    "# elif CFG[\"task\"] == \"binary\":\n",
    "#     pred = loaded.predict_proba(new_X)[:, 1]\n",
    "# else:\n",
    "#     pred = loaded.predict_proba(new_X)\n",
    "\n",
    "# pd.DataFrame({\"pred\": pred}).to_csv(ART / \"predictions.csv\", index=False)\n",
    "# print(\"saved:\", ART / \"predictions.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7be601a6",
   "metadata": {},
   "source": [
    "## 14. 现场收尾清单（打印在脑子里）\n",
    "- 跑通 baseline（有分数）\n",
    "- 切分无泄露（时间/分组）\n",
    "- 类别列 category（或 one-hot 备胎）\n",
    "- early stopping 选最佳轮次\n",
    "- 重要性 + 错误切片\n",
    "- artifacts：model.pkl / config.json / feature_importance.csv / predictions.csv"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
