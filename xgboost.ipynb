{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Dataset Interview：XGBoost 训练与部署速查（现场用）\n\n本 notebook 用于在现场快速完成：  \n- 数据加载与快速检查  \n- 时序切分 / 验证  \n- 特征工程（lag / rolling / 日历特征）  \n- XGBoost 训练（early stopping）  \n- 误差诊断与可解释性  \n- 模型保存与复现\n\n> 目标：用最少步骤跑出可靠 baseline，然后做 2–3 次有方向的参数试验并能解释。\n"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": "# ====== 环境自检（按需执行）======\nimport sys, os, platform, time\nprint(\"python:\", sys.version.split()[0])\nprint(\"platform:\", platform.platform())\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 0. 依赖导入 & 全局设置\n- 树模型不依赖标准化  \n- 缺失值保留为 NaN，XGBoost 可直接处理  \n- 类别特征默认 one-hot（高基数先做合并/截断）\n"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": "import numpy as np\nimport pandas as pd\n\nfrom sklearn.model_selection import TimeSeriesSplit\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error, roc_auc_score, log_loss\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\n\nimport matplotlib.pyplot as plt\n\n# xgboost\nimport xgboost as xgb\n\npd.set_option(\"display.max_columns\", 200)\npd.set_option(\"display.width\", 140)\n\nRANDOM_SEED = 42\nnp.random.seed(RANDOM_SEED)\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 1. 数据读取（按实际文件改路径/格式）\n约定：\n- 时间列：`time_col`\n- 目标列：`target_col`\n- 可选 ID 列：`id_col`（如资产/站点/用户等）\n"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": "# ====== 修改这里 ======\nDATA_PATH = \"data.csv\"      # e.g., \"train.parquet\" / \"train.csv\"\ntime_col = \"timestamp\"\ntarget_col = \"y\"\nid_col = None               # e.g., \"asset_id\"; 无则填 None\n\n# ====== 读取 ======\ndef load_data(path: str) -> pd.DataFrame:\n    ext = os.path.splitext(path)[1].lower()\n    if ext in [\".parquet\"]:\n        return pd.read_parquet(path)\n    if ext in [\".csv\"]:\n        return pd.read_csv(path)\n    if ext in [\".feather\"]:\n        return pd.read_feather(path)\n    raise ValueError(f\"Unsupported file type: {ext}\")\n\ndf = load_data(DATA_PATH)\nprint(df.shape)\ndf.head()\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 2. 快速体检：类型/缺失/重复/目标分布\n"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": "def quick_profile(df: pd.DataFrame, target_col: str | None = None):\n    out = {}\n    out[\"n_rows\"] = len(df)\n    out[\"n_cols\"] = df.shape[1]\n    out[\"dup_rows\"] = int(df.duplicated().sum())\n    na_rate = df.isna().mean().sort_values(ascending=False)\n    out[\"top_na\"] = na_rate.head(10)\n    dtypes = df.dtypes.astype(str).value_counts()\n    out[\"dtypes\"] = dtypes\n    if target_col and target_col in df.columns:\n        y = df[target_col]\n        out[\"target_na\"] = float(y.isna().mean())\n        if pd.api.types.is_numeric_dtype(y):\n            out[\"target_desc\"] = y.describe()\n        else:\n            out[\"target_value_counts\"] = y.value_counts(dropna=False).head(10)\n    return out\n\nprof = quick_profile(df, target_col)\nprint(\"rows/cols:\", prof[\"n_rows\"], prof[\"n_cols\"])\nprint(\"dup_rows:\", prof[\"dup_rows\"])\nprint(\"\\n== dtype counts ==\")\nprint(prof[\"dtypes\"])\nprint(\"\\n== top missing columns ==\")\nprint(prof[\"top_na\"])\n"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": "# 时间列标准化为 pandas datetime（按实际格式调整）\ndf[time_col] = pd.to_datetime(df[time_col], errors=\"coerce\")\ndf = df.sort_values(time_col).reset_index(drop=True)\n\nprint(\"time min/max:\", df[time_col].min(), df[time_col].max())\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### 2.1 目标列快速图（回归）\n"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": "if target_col in df.columns and pd.api.types.is_numeric_dtype(df[target_col]):\n    plt.figure()\n    df[target_col].hist(bins=50)\n    plt.title(\"Target distribution\")\n    plt.show()\n\n    # 时间趋势（粗看）\n    plt.figure()\n    df.set_index(time_col)[target_col].rolling(100).mean().plot()\n    plt.title(\"Target rolling mean (window=100)\")\n    plt.show()\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 3. 时序切分：Train / Valid / Test\n- 不 shuffle  \n- 用最后一段做 valid/test，或用 walk-forward 做 CV\n"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": "# ====== 修改这里：按题目定义划分比例或固定日期 ======\ntrain_frac = 0.7\nvalid_frac = 0.15\n\nn = len(df)\ni_train_end = int(n * train_frac)\ni_valid_end = int(n * (train_frac + valid_frac))\n\ndf_train = df.iloc[:i_train_end].copy()\ndf_valid = df.iloc[i_train_end:i_valid_end].copy()\ndf_test  = df.iloc[i_valid_end:].copy()\n\nprint(\"train/valid/test:\", df_train.shape, df_valid.shape, df_test.shape)\nprint(\"train time:\", df_train[time_col].min(), \"->\", df_train[time_col].max())\nprint(\"valid time:\", df_valid[time_col].min(), \"->\", df_valid[time_col].max())\nprint(\"test  time:\", df_test[time_col].min(),  \"->\", df_test[time_col].max())\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 4. 特征工程（通用 + 时序）\n### 4.1 日历特征（时间戳）\n"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": "def add_time_features(df: pd.DataFrame, time_col: str) -> pd.DataFrame:\n    t = df[time_col]\n    out = df.copy()\n    out[\"hour\"] = t.dt.hour\n    out[\"dayofweek\"] = t.dt.dayofweek\n    out[\"day\"] = t.dt.day\n    out[\"month\"] = t.dt.month\n    out[\"is_month_start\"] = t.dt.is_month_start.astype(int)\n    out[\"is_month_end\"] = t.dt.is_month_end.astype(int)\n    return out\n\ndf_train_fe = add_time_features(df_train, time_col)\ndf_valid_fe = add_time_features(df_valid, time_col)\ndf_test_fe  = add_time_features(df_test,  time_col)\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### 4.2 Lag / Rolling（按实体分组或全局）\n- 若存在 `id_col`：按实体分组做 lag/rolling  \n- 否则：视为单序列\n"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": "# ====== 修改这里：选取要做 lag/rolling 的数值列 ======\n# 默认：除了 time/target/id 之外的数值列\nexclude_cols = {time_col, target_col}\nif id_col:\n    exclude_cols.add(id_col)\n\nnumeric_cols = [c for c in df.columns if c not in exclude_cols and pd.api.types.is_numeric_dtype(df[c])]\nprint(\"numeric feature cols:\", len(numeric_cols))\nnumeric_cols[:20]\n"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": "def add_lag_rolling(df: pd.DataFrame, time_col: str, cols: list[str], id_col: str | None = None,\n                    lags=(1,2,3,5,10), windows=(5,10,20)):\n    out = df.sort_values([id_col, time_col] if id_col else [time_col]).copy()\n    grp = out.groupby(id_col, sort=False) if id_col else [(None, out)]\n\n    for col in cols:\n        if id_col:\n            g = out.groupby(id_col, sort=False)[col]\n        else:\n            g = out[col]\n\n        for L in lags:\n            out[f\"{col}_lag{L}\"] = g.shift(L)\n\n        for W in windows:\n            # rolling stats on shifted series to avoid leakage at time t\n            s = g.shift(1)\n            if id_col:\n                out[f\"{col}_rmean{W}\"] = s.groupby(out[id_col]).rolling(W, min_periods=max(2, W//3)).mean().reset_index(level=0, drop=True)\n                out[f\"{col}_rstd{W}\"]  = s.groupby(out[id_col]).rolling(W, min_periods=max(2, W//3)).std().reset_index(level=0, drop=True)\n            else:\n                out[f\"{col}_rmean{W}\"] = s.rolling(W, min_periods=max(2, W//3)).mean()\n                out[f\"{col}_rstd{W}\"]  = s.rolling(W, min_periods=max(2, W//3)).std()\n    return out\n\ndf_train_fe = add_lag_rolling(df_train_fe, time_col, numeric_cols, id_col=id_col)\ndf_valid_fe = add_lag_rolling(df_valid_fe, time_col, numeric_cols, id_col=id_col)\ndf_test_fe  = add_lag_rolling(df_test_fe,  time_col, numeric_cols, id_col=id_col)\n\nprint(df_train_fe.shape, df_valid_fe.shape, df_test_fe.shape)\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### 4.3 丢掉因 lag/rolling 产生的前几行 NaN（训练/验证要一致）\n"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": "# 以 target 非空为基本要求；同时允许特征存在 NaN（XGB 可处理）\ndef clean_frame(df: pd.DataFrame, target_col: str):\n    out = df.copy()\n    out = out[~out[target_col].isna()].copy()\n    return out\n\ndf_train_fe = clean_frame(df_train_fe, target_col)\ndf_valid_fe = clean_frame(df_valid_fe, target_col)\ndf_test_fe  = clean_frame(df_test_fe,  target_col)\n\nprint(\"after clean:\", df_train_fe.shape, df_valid_fe.shape, df_test_fe.shape)\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 5. 特征列整理：数值 + 类别\n"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": "# 类别列：object/category/bool\nbase_exclude = {target_col, time_col}\nif id_col:\n    base_exclude.add(id_col)\n\ncat_cols = [c for c in df_train_fe.columns\n            if c not in base_exclude and (df_train_fe[c].dtype == \"object\" or str(df_train_fe[c].dtype) == \"category\" or df_train_fe[c].dtype == \"bool\")]\n\n# 数值列：其余\nfeat_cols = [c for c in df_train_fe.columns if c not in base_exclude]\nnum_cols = [c for c in feat_cols if c not in cat_cols and pd.api.types.is_numeric_dtype(df_train_fe[c])]\n\nprint(\"features:\", len(feat_cols), \"num:\", len(num_cols), \"cat:\", len(cat_cols))\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 6. 建模任务类型\n- 回归：`task = \"reg\"`  \n- 二分类：`task = \"clf_bin\"`（y 取 {0,1}）  \n- 多分类：`task = \"clf_multi\"`（y 为 0..K-1）\n"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": "task = \"reg\"   # \"reg\" / \"clf_bin\" / \"clf_multi\"\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 7. Pipeline：one-hot + XGBoost（Sklearn API）\n- 现场优先用 Pipeline，便于保存与复现  \n- XGBoost 接受稀疏矩阵输入\n"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": "preprocess = ColumnTransformer(\n    transformers=[\n        (\"num\", \"passthrough\", num_cols),\n        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=True), cat_cols),\n    ],\n    remainder=\"drop\",\n)\n\ndef build_model(task: str):\n    if task == \"reg\":\n        return xgb.XGBRegressor(\n            n_estimators=3000,\n            learning_rate=0.03,\n            max_depth=6,\n            subsample=0.8,\n            colsample_bytree=0.8,\n            min_child_weight=5,\n            reg_alpha=0.0,\n            reg_lambda=1.0,\n            gamma=0.0,\n            tree_method=\"hist\",\n            random_state=RANDOM_SEED,\n            n_jobs=-1,\n        )\n    if task == \"clf_bin\":\n        return xgb.XGBClassifier(\n            n_estimators=3000,\n            learning_rate=0.03,\n            max_depth=6,\n            subsample=0.8,\n            colsample_bytree=0.8,\n            min_child_weight=5,\n            reg_alpha=0.0,\n            reg_lambda=1.0,\n            gamma=0.0,\n            tree_method=\"hist\",\n            random_state=RANDOM_SEED,\n            n_jobs=-1,\n            eval_metric=\"logloss\",\n        )\n    if task == \"clf_multi\":\n        # num_class 后面根据 y 自动推断\n        return xgb.XGBClassifier(\n            n_estimators=3000,\n            learning_rate=0.03,\n            max_depth=6,\n            subsample=0.8,\n            colsample_bytree=0.8,\n            min_child_weight=5,\n            reg_alpha=0.0,\n            reg_lambda=1.0,\n            gamma=0.0,\n            tree_method=\"hist\",\n            random_state=RANDOM_SEED,\n            n_jobs=-1,\n            objective=\"multi:softprob\",\n            eval_metric=\"mlogloss\",\n        )\n    raise ValueError(task)\n\nmodel = build_model(task)\n\npipe = Pipeline(steps=[\n    (\"prep\", preprocess),\n    (\"model\", model)\n])\n\nX_train = df_train_fe[feat_cols]\ny_train = df_train_fe[target_col]\nX_valid = df_valid_fe[feat_cols]\ny_valid = df_valid_fe[target_col]\nX_test  = df_test_fe[feat_cols]\ny_test  = df_test_fe[target_col]\n\nprint(X_train.shape, X_valid.shape, X_test.shape)\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 8. 训练（early stopping）\nXGBoost 的 early stopping 需要把 eval_set 传进模型 fit。  \nPipeline 下通过 `model__` 前缀传参。\n"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": "fit_params = dict(\n    model__eval_set=[(X_valid, y_valid)],\n    model__verbose=200,\n    model__early_stopping_rounds=200,\n)\n\nt0 = time.time()\npipe.fit(X_train, y_train, **fit_params)\nprint(\"train seconds:\", round(time.time() - t0, 2))\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 9. 评估：Valid/Test 指标 + 简单诊断\n"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": "def eval_reg(y_true, y_pred, name=\"\"):\n    rmse = mean_squared_error(y_true, y_pred, squared=False)\n    mae = mean_absolute_error(y_true, y_pred)\n    print(f\"{name} RMSE={rmse:.6g}  MAE={mae:.6g}\")\n    return {\"rmse\": rmse, \"mae\": mae}\n\ndef eval_bin(y_true, y_proba, name=\"\"):\n    # y_proba: P(y=1)\n    auc = roc_auc_score(y_true, y_proba)\n    ll = log_loss(y_true, y_proba)\n    print(f\"{name} AUC={auc:.6g}  logloss={ll:.6g}\")\n    return {\"auc\": auc, \"logloss\": ll}\n\n# valid\nif task == \"reg\":\n    pred_v = pipe.predict(X_valid)\n    m_valid = eval_reg(y_valid, pred_v, \"valid\")\nelif task == \"clf_bin\":\n    proba_v = pipe.predict_proba(X_valid)[:, 1]\n    m_valid = eval_bin(y_valid, proba_v, \"valid\")\nelif task == \"clf_multi\":\n    proba_v = pipe.predict_proba(X_valid)\n    ll = log_loss(y_valid, proba_v)\n    print(f\"valid mlogloss={ll:.6g}\")\n    m_valid = {\"mlogloss\": ll}\n\n# test\nif task == \"reg\":\n    pred_t = pipe.predict(X_test)\n    m_test = eval_reg(y_test, pred_t, \"test\")\nelif task == \"clf_bin\":\n    proba_t = pipe.predict_proba(X_test)[:, 1]\n    m_test = eval_bin(y_test, proba_t, \"test\")\nelif task == \"clf_multi\":\n    proba_t = pipe.predict_proba(X_test)\n    ll = log_loss(y_test, proba_t)\n    print(f\"test mlogloss={ll:.6g}\")\n    m_test = {\"mlogloss\": ll}\n"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": "# 残差图（回归）\nif task == \"reg\":\n    res = (y_test.values - pred_t)\n    plt.figure()\n    plt.hist(res, bins=60)\n    plt.title(\"Residuals on test\")\n    plt.show()\n\n    # 残差随时间漂移（粗查）\n    tmp = df_test_fe[[time_col]].copy()\n    tmp[\"residual\"] = res\n    plt.figure()\n    tmp.set_index(time_col)[\"residual\"].rolling(100).mean().plot()\n    plt.title(\"Residual rolling mean (test, window=100)\")\n    plt.show()\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 10. 特征重要性（gain / weight）\nPipeline 下取出训练后的 booster：\n"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": "# 取出训练后的 XGBoost 模型\nxgb_model = pipe.named_steps[\"model\"]\n\n# 重要性（sklearn feature_importances_ 是按处理后的列；one-hot 后列名需要从 encoder 拿）\n# 这里给出可复现的 feature name 展开\nprep = pipe.named_steps[\"prep\"]\nfeature_names = []\n\n# num\nfeature_names.extend(num_cols)\n\n# cat one-hot\nif len(cat_cols) > 0:\n    ohe = prep.named_transformers_[\"cat\"]\n    ohe_names = list(ohe.get_feature_names_out(cat_cols))\n    feature_names.extend(ohe_names)\n\nimp = pd.Series(xgb_model.feature_importances_, index=feature_names).sort_values(ascending=False)\nimp.head(25)\n"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": "# 画 top20\ntopk = 20\nplt.figure()\nimp.head(topk)[::-1].plot(kind=\"barh\")\nplt.title(f\"Top {topk} feature importance\")\nplt.show()\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 11. 参数试验（控制变量：2–3 次即可）\n目标：验证“更保守/更激进”对过拟合与泛化的影响。\n\n这里用一组试验表驱动训练，输出 valid 指标对比。\n"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": "from copy import deepcopy\n\ndef clone_pipe_with_params(pipe: Pipeline, params: dict):\n    p2 = deepcopy(pipe)\n    p2.set_params(**params)\n    return p2\n\ntrials = [\n    (\"baseline\", {}),\n    (\"shallower\", {\"model__max_depth\": 4}),\n    (\"more_reg\",  {\"model__min_child_weight\": 10, \"model__gamma\": 1.0}),\n]\n\nresults = []\n\nfor name, p in trials:\n    p2 = clone_pipe_with_params(pipe, p)\n    t0 = time.time()\n    p2.fit(X_train, y_train, **fit_params)\n    sec = time.time() - t0\n\n    if task == \"reg\":\n        pv = p2.predict(X_valid)\n        rmse = mean_squared_error(y_valid, pv, squared=False)\n        results.append((name, rmse, sec))\n    elif task == \"clf_bin\":\n        pv = p2.predict_proba(X_valid)[:, 1]\n        ll = log_loss(y_valid, pv)\n        results.append((name, ll, sec))\n    else:\n        pv = p2.predict_proba(X_valid)\n        ll = log_loss(y_valid, pv)\n        results.append((name, ll, sec))\n\nres_df = pd.DataFrame(results, columns=[\"trial\", \"valid_metric\", \"train_seconds\"]).sort_values(\"valid_metric\")\nres_df\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 12. 保存模型（含预处理）\nPipeline 直接用 joblib 保存，现场最稳。\n"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": "import joblib\n\nOUT_DIR = \"artifacts\"\nos.makedirs(OUT_DIR, exist_ok=True)\n\nmodel_path = os.path.join(OUT_DIR, \"xgb_pipeline.joblib\")\njoblib.dump(pipe, model_path)\n\n# 也保存一个 xgboost 原生模型（可选）\nxgb_native_path = os.path.join(OUT_DIR, \"xgb_native.json\")\npipe.named_steps[\"model\"].save_model(xgb_native_path)\n\nprint(\"saved:\", model_path)\nprint(\"saved:\", xgb_native_path)\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 13. 复现加载（自检）\n"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": "pipe2 = joblib.load(model_path)\n\nif task == \"reg\":\n    p = pipe2.predict(X_test)\n    eval_reg(y_test, p, \"loaded test\")\nelif task == \"clf_bin\":\n    p = pipe2.predict_proba(X_test)[:, 1]\n    eval_bin(y_test, p, \"loaded test\")\nelse:\n    p = pipe2.predict_proba(X_test)\n    ll = log_loss(y_test, p)\n    print(f\"loaded test mlogloss={ll:.6g}\")\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 14. 最终汇报结构（PPT/口述提纲）\n- 问题定义与目标指标  \n- 数据概览：时间范围、缺失、分布、潜在泄漏点  \n- 验证方式：按时间切分 / walk-forward  \n- Baseline：最小特征集 + early stopping  \n- 改进：两到三组有方向的超参试验（更保守/更激进）  \n- 结果：valid/test 指标、误差分桶（按时间/分位数/类别）  \n- 可解释性：Top features + 合理解释  \n- 下一步：更精细的特征、分层建模、稳定性评估\n"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.x"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}