{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a20b602",
   "metadata": {},
   "source": [
    "# Dataset Interview — NN 部署与训练速查（现场参考）\n",
    "\n",
    "（本 notebook 用作现场“流程清单 + 可直接运行的最小模板”。按数据情况删改即可。）\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77db46b8",
   "metadata": {},
   "source": [
    "## 0. 运行开关（任务类型 / 切分方式）\n",
    "\n",
    "- `TASK`: `\"regression\" | \"binary\" | \"multiclass\"`\n",
    "- `SPLIT`: `\"time\" | \"random\"`\n",
    "- `TARGET_COL`: 目标列名\n",
    "- `TIME_COL`: 时间列名（时序切分用）\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73575484",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====== 配置区：按数据修改 ======\n",
    "TASK = \"regression\"      # \"regression\" | \"binary\" | \"multiclass\"\n",
    "SPLIT = \"time\"           # \"time\" | \"random\"\n",
    "TARGET_COL = \"y\"\n",
    "TIME_COL = \"timestamp\"   # SPLIT=\"time\" 时使用\n",
    "\n",
    "# 多分类时：类别数 K（也可在数据读入后自动推断）\n",
    "NUM_CLASSES = None\n",
    "\n",
    "# 训练超参（现场优先稳定）\n",
    "SEED = 42\n",
    "BATCH_SIZE = 512\n",
    "LR = 1e-3\n",
    "WEIGHT_DECAY = 1e-4\n",
    "EPOCHS = 50\n",
    "PATIENCE = 5\n",
    "GRAD_CLIP = 1.0\n",
    "\n",
    "# 资源\n",
    "USE_GPU = True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5b0234f",
   "metadata": {},
   "source": [
    "## 1. 环境检查 + 依赖导入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c25eaf05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, platform, os, math, random, time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "print(\"Python:\", sys.version.split()[0])\n",
    "print(\"Platform:\", platform.platform())\n",
    "print(\"Working dir:\", os.getcwd())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2867a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 核心依赖：sklearn + torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.metrics import log_loss, roc_auc_score, accuracy_score, f1_score\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "device = torch.device(\"cuda\" if (USE_GPU and torch.cuda.is_available()) else \"cpu\")\n",
    "print(\"Device:\", device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7393092c",
   "metadata": {},
   "source": [
    "## 2. 可复现性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f37fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "seed_everything(SEED)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0082e491",
   "metadata": {},
   "source": [
    "## 3. 读入数据（占位）\n",
    "\n",
    "- 支持 `csv / parquet / feather` 等\n",
    "- 读入后确保包含 `TARGET_COL`，时序任务确保包含 `TIME_COL`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c9e6e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====== 数据读入：按实际路径改 ======\n",
    "# df = pd.read_csv(\"data.csv\")\n",
    "# df = pd.read_parquet(\"data.parquet\")\n",
    "\n",
    "df = None  # 读入后替换\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98513dc9",
   "metadata": {},
   "source": [
    "## 4. 基础检查（缺失 / 类型 / 目标分布）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecbb6582",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert df is not None, \"先在上一个 cell 读入 df\"\n",
    "\n",
    "print(\"shape:\", df.shape)\n",
    "print(df.head(3))\n",
    "\n",
    "print(\"\\nMissing ratio (top 20):\")\n",
    "miss = df.isna().mean().sort_values(ascending=False)\n",
    "display(miss.head(20))\n",
    "\n",
    "print(\"\\nDtypes (top 30):\")\n",
    "display(df.dtypes.head(30))\n",
    "\n",
    "assert TARGET_COL in df.columns, f\"缺少目标列 {TARGET_COL}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "367508d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_raw = df[TARGET_COL]\n",
    "print(\"Target describe:\")\n",
    "display(y_raw.describe(include=\"all\"))\n",
    "\n",
    "if TASK in [\"binary\", \"multiclass\"]:\n",
    "    print(\"Target value counts (top 20):\")\n",
    "    display(y_raw.value_counts().head(20))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2ca43aa",
   "metadata": {},
   "source": [
    "## 5. 切分（时序 / 随机）\n",
    "\n",
    "- 时序切分：按 `TIME_COL` 排序，前 80% train，后 20% valid（可改）\n",
    "- 随机切分：`train_test_split`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9aeff3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_split(df, time_col, frac=0.8):\n",
    "    d = df.sort_values(time_col).reset_index(drop=True)\n",
    "    n = len(d)\n",
    "    cut = int(n * frac)\n",
    "    train_df = d.iloc[:cut].copy()\n",
    "    val_df = d.iloc[cut:].copy()\n",
    "    return train_df, val_df\n",
    "\n",
    "if SPLIT == \"time\":\n",
    "    assert TIME_COL in df.columns, f\"SPLIT='time' 需要 {TIME_COL}\"\n",
    "    train_df, val_df = time_split(df, TIME_COL, frac=0.8)\n",
    "else:\n",
    "    train_df, val_df = train_test_split(df, test_size=0.2, random_state=SEED, shuffle=True)\n",
    "\n",
    "print(\"train:\", train_df.shape, \"val:\", val_df.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d0dab07",
   "metadata": {},
   "source": [
    "## 6. 特征 / 目标拆分 + 预处理（sklearn 管道）\n",
    "\n",
    "- 数值列：median 填充 + 标准化\n",
    "- 类别列：most_frequent 填充 + OneHot\n",
    "- 预处理只在 train fit，再 transform val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb71888a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_preprocessor(train_df, target_col):\n",
    "    X = train_df.drop(columns=[target_col])\n",
    "    numeric_cols = X.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    categorical_cols = [c for c in X.columns if c not in numeric_cols]\n",
    "\n",
    "    numeric_pipe = Pipeline(steps=[\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"scaler\", StandardScaler(with_mean=True, with_std=True)),\n",
    "    ])\n",
    "    categorical_pipe = Pipeline(steps=[\n",
    "        (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "        (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=True)),\n",
    "    ])\n",
    "\n",
    "    pre = ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"num\", numeric_pipe, numeric_cols),\n",
    "            (\"cat\", categorical_pipe, categorical_cols),\n",
    "        ],\n",
    "        remainder=\"drop\",\n",
    "        sparse_threshold=0.3,\n",
    "    )\n",
    "    return pre, numeric_cols, categorical_cols\n",
    "\n",
    "preprocessor, num_cols, cat_cols = build_preprocessor(train_df, TARGET_COL)\n",
    "print(\"num cols:\", len(num_cols), \"cat cols:\", len(cat_cols))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "912843a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_xy(train_df, val_df, preprocessor, target_col):\n",
    "    X_train_raw = train_df.drop(columns=[target_col])\n",
    "    y_train_raw = train_df[target_col].copy()\n",
    "\n",
    "    X_val_raw = val_df.drop(columns=[target_col])\n",
    "    y_val_raw = val_df[target_col].copy()\n",
    "\n",
    "    X_train = preprocessor.fit_transform(X_train_raw)\n",
    "    X_val = preprocessor.transform(X_val_raw)\n",
    "\n",
    "    return X_train, y_train_raw, X_val, y_val_raw\n",
    "\n",
    "X_train_sp, y_train_raw, X_val_sp, y_val_raw = prepare_xy(train_df, val_df, preprocessor, TARGET_COL)\n",
    "print(\"X_train type:\", type(X_train_sp), \"shape:\", X_train_sp.shape)\n",
    "print(\"X_val   type:\", type(X_val_sp), \"shape:\", X_val_sp.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85b9faf0",
   "metadata": {},
   "source": [
    "## 7. 目标编码（分类）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6848b405",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder = None\n",
    "\n",
    "if TASK == \"binary\":\n",
    "    # 假设目标是 {0,1} 或 {False,True} 或两类字符串\n",
    "    le = LabelEncoder()\n",
    "    y_train = le.fit_transform(y_train_raw.astype(str))\n",
    "    y_val = le.transform(y_val_raw.astype(str))\n",
    "    label_encoder = le\n",
    "    assert set(np.unique(y_train)).issubset({0,1}), \"binary 目标编码异常\"\n",
    "elif TASK == \"multiclass\":\n",
    "    le = LabelEncoder()\n",
    "    y_train = le.fit_transform(y_train_raw.astype(str))\n",
    "    y_val = le.transform(y_val_raw.astype(str))\n",
    "    label_encoder = le\n",
    "    K = int(np.max(y_train) + 1) if NUM_CLASSES is None else int(NUM_CLASSES)\n",
    "    NUM_CLASSES = K\n",
    "    print(\"NUM_CLASSES:\", NUM_CLASSES)\n",
    "else:\n",
    "    # regression\n",
    "    y_train = y_train_raw.astype(float).to_numpy()\n",
    "    y_val = y_val_raw.astype(float).to_numpy()\n",
    "\n",
    "print(\"y_train shape:\", np.shape(y_train), \"y_val shape:\", np.shape(y_val))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae43da6",
   "metadata": {},
   "source": [
    "## 8. Sparse → dense（小心内存）\n",
    "\n",
    "- 预处理后可能得到稀疏矩阵；MLP 训练通常用 dense float32\n",
    "- 维度过大时：先 baseline 或改用 embedding（需要额外工程）\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fda0c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_dense_float32(X):\n",
    "    # X: scipy sparse or numpy\n",
    "    if hasattr(X, \"toarray\"):\n",
    "        X = X.toarray()\n",
    "    return np.asarray(X, dtype=np.float32)\n",
    "\n",
    "X_train = to_dense_float32(X_train_sp)\n",
    "X_val = to_dense_float32(X_val_sp)\n",
    "\n",
    "print(\"Dense shapes:\", X_train.shape, X_val.shape, \"dtype:\", X_train.dtype)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05148f03",
   "metadata": {},
   "source": [
    "## 9. Baseline（sklearn，1 分钟拿结果）\n",
    "\n",
    "- regression: Ridge\n",
    "- binary/multiclass: LogisticRegression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c0c7cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge, LogisticRegression\n",
    "\n",
    "def eval_regression(y_true, y_pred):\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    rmse = math.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    return {\"MAE\": mae, \"RMSE\": rmse, \"R2\": r2}\n",
    "\n",
    "def eval_binary(y_true, prob):\n",
    "    # prob: P(y=1)\n",
    "    ll = log_loss(y_true, prob, labels=[0,1])\n",
    "    auc = roc_auc_score(y_true, prob)\n",
    "    pred = (prob >= 0.5).astype(int)\n",
    "    acc = accuracy_score(y_true, pred)\n",
    "    f1 = f1_score(y_true, pred)\n",
    "    return {\"LogLoss\": ll, \"AUC\": auc, \"Acc\": acc, \"F1\": f1}\n",
    "\n",
    "def eval_multiclass(y_true, prob):\n",
    "    # prob: (n, K)\n",
    "    ll = log_loss(y_true, prob)\n",
    "    pred = prob.argmax(axis=1)\n",
    "    acc = accuracy_score(y_true, pred)\n",
    "    f1 = f1_score(y_true, pred, average=\"macro\")\n",
    "    return {\"LogLoss\": ll, \"Acc\": acc, \"MacroF1\": f1}\n",
    "\n",
    "if TASK == \"regression\":\n",
    "    base = Ridge(alpha=1.0, random_state=SEED)\n",
    "    base.fit(X_train, y_train)\n",
    "    pred = base.predict(X_val)\n",
    "    baseline_metrics = eval_regression(y_val, pred)\n",
    "elif TASK == \"binary\":\n",
    "    base = LogisticRegression(max_iter=500, n_jobs=-1)\n",
    "    base.fit(X_train, y_train)\n",
    "    prob = base.predict_proba(X_val)[:, 1]\n",
    "    baseline_metrics = eval_binary(y_val, prob)\n",
    "else:\n",
    "    base = LogisticRegression(max_iter=500, n_jobs=-1, multi_class=\"auto\")\n",
    "    base.fit(X_train, y_train)\n",
    "    prob = base.predict_proba(X_val)\n",
    "    baseline_metrics = eval_multiclass(y_val, prob)\n",
    "\n",
    "baseline_metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a1358e3",
   "metadata": {},
   "source": [
    "## 10. PyTorch Dataset / DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a81a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NpDataset(Dataset):\n",
    "    def __init__(self, X, y, task):\n",
    "        self.X = torch.tensor(X, dtype=torch.float32)\n",
    "        self.task = task\n",
    "        if task == \"regression\":\n",
    "            self.y = torch.tensor(y, dtype=torch.float32)\n",
    "        elif task == \"binary\":\n",
    "            self.y = torch.tensor(y, dtype=torch.float32)  # BCEWithLogitsLoss\n",
    "        else:\n",
    "            self.y = torch.tensor(y, dtype=torch.long)     # CrossEntropyLoss\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.X.shape[0]\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return self.X[i], self.y[i]\n",
    "\n",
    "train_loader = DataLoader(NpDataset(X_train, y_train, TASK), batch_size=BATCH_SIZE, shuffle=True, drop_last=False)\n",
    "val_loader   = DataLoader(NpDataset(X_val,   y_val,   TASK), batch_size=4096,      shuffle=False, drop_last=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b3561b2",
   "metadata": {},
   "source": [
    "## 11. MLP 模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc9e4822",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, d_in, d_out, hidden=(256, 128), dropout=0.1):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        prev = d_in\n",
    "        for h in hidden:\n",
    "            layers += [nn.Linear(prev, h), nn.ReLU(), nn.Dropout(dropout)]\n",
    "            prev = h\n",
    "        layers += [nn.Linear(prev, d_out)]\n",
    "        self.net = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "d_in = X_train.shape[1]\n",
    "if TASK == \"regression\":\n",
    "    d_out = 1\n",
    "elif TASK == \"binary\":\n",
    "    d_out = 1\n",
    "else:\n",
    "    assert NUM_CLASSES is not None, \"multiclass 需要 NUM_CLASSES\"\n",
    "    d_out = int(NUM_CLASSES)\n",
    "\n",
    "model = MLP(d_in=d_in, d_out=d_out, hidden=(256,128), dropout=0.1).to(device)\n",
    "model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e1d0844",
   "metadata": {},
   "source": [
    "## 12. Loss / 优化器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a524c666",
   "metadata": {},
   "outputs": [],
   "source": [
    "if TASK == \"regression\":\n",
    "    loss_fn = nn.SmoothL1Loss()\n",
    "elif TASK == \"binary\":\n",
    "    loss_fn = nn.BCEWithLogitsLoss()\n",
    "else:\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e162342e",
   "metadata": {},
   "source": [
    "## 13. 训练循环（early stopping + gradient clip）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9fc585d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, loader, optimizer, loss_fn, device):\n",
    "    model.train()\n",
    "    total, n = 0.0, 0\n",
    "    for Xb, yb in loader:\n",
    "        Xb = Xb.to(device)\n",
    "        yb = yb.to(device)\n",
    "\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        logits = model(Xb)\n",
    "\n",
    "        if TASK == \"regression\":\n",
    "            loss = loss_fn(logits.squeeze(-1), yb)\n",
    "        elif TASK == \"binary\":\n",
    "            loss = loss_fn(logits.squeeze(-1), yb)\n",
    "        else:\n",
    "            loss = loss_fn(logits, yb)\n",
    "\n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), GRAD_CLIP)\n",
    "        optimizer.step()\n",
    "\n",
    "        bs = Xb.size(0)\n",
    "        total += loss.item() * bs\n",
    "        n += bs\n",
    "    return total / max(n, 1)\n",
    "\n",
    "@torch.no_grad()\n",
    "def eval_one_epoch(model, loader, loss_fn, device):\n",
    "    model.eval()\n",
    "    total, n = 0.0, 0\n",
    "    for Xb, yb in loader:\n",
    "        Xb = Xb.to(device)\n",
    "        yb = yb.to(device)\n",
    "        logits = model(Xb)\n",
    "\n",
    "        if TASK == \"regression\":\n",
    "            loss = loss_fn(logits.squeeze(-1), yb)\n",
    "        elif TASK == \"binary\":\n",
    "            loss = loss_fn(logits.squeeze(-1), yb)\n",
    "        else:\n",
    "            loss = loss_fn(logits, yb)\n",
    "\n",
    "        bs = Xb.size(0)\n",
    "        total += loss.item() * bs\n",
    "        n += bs\n",
    "    return total / max(n, 1)\n",
    "\n",
    "def fit(model, train_loader, val_loader, loss_fn, optimizer, device, epochs=50, patience=5):\n",
    "    best = float(\"inf\")\n",
    "    best_state = None\n",
    "    bad = 0\n",
    "    hist = []\n",
    "\n",
    "    for ep in range(1, epochs + 1):\n",
    "        t0 = time.time()\n",
    "        tr = train_one_epoch(model, train_loader, optimizer, loss_fn, device)\n",
    "        va = eval_one_epoch(model, val_loader, loss_fn, device)\n",
    "        dt = time.time() - t0\n",
    "\n",
    "        hist.append({\"epoch\": ep, \"train_loss\": tr, \"val_loss\": va, \"sec\": dt})\n",
    "        print(f\"ep {ep:03d} | train {tr:.6f} | val {va:.6f} | {dt:.1f}s\")\n",
    "\n",
    "        if va < best - 1e-6:\n",
    "            best = va\n",
    "            best_state = {k: v.detach().cpu().clone() for k, v in model.state_dict().items()}\n",
    "            bad = 0\n",
    "        else:\n",
    "            bad += 1\n",
    "\n",
    "        if bad >= patience:\n",
    "            print(\"early stop\")\n",
    "            break\n",
    "\n",
    "    if best_state is not None:\n",
    "        model.load_state_dict(best_state)\n",
    "    return pd.DataFrame(hist), best\n",
    "\n",
    "hist_df, best_val_loss = fit(model, train_loader, val_loader, loss_fn, optimizer, device, epochs=EPOCHS, patience=PATIENCE)\n",
    "best_val_loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12d1c309",
   "metadata": {},
   "source": [
    "## 14. 推断与指标评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c3bee98",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def predict(model, X, device, batch_size=4096):\n",
    "    model.eval()\n",
    "    X_t = torch.tensor(X, dtype=torch.float32)\n",
    "    loader = DataLoader(X_t, batch_size=batch_size, shuffle=False)\n",
    "    outs = []\n",
    "    for xb in loader:\n",
    "        xb = xb.to(device)\n",
    "        outs.append(model(xb).detach().cpu())\n",
    "    return torch.cat(outs, dim=0)\n",
    "\n",
    "logits = predict(model, X_val, device=device)\n",
    "\n",
    "if TASK == \"regression\":\n",
    "    y_pred = logits.squeeze(-1).numpy()\n",
    "    nn_metrics = eval_regression(y_val, y_pred)\n",
    "\n",
    "elif TASK == \"binary\":\n",
    "    prob = torch.sigmoid(logits.squeeze(-1)).numpy()\n",
    "    nn_metrics = eval_binary(y_val, prob)\n",
    "\n",
    "else:\n",
    "    prob = torch.softmax(logits, dim=1).numpy()\n",
    "    nn_metrics = eval_multiclass(y_val, prob)\n",
    "\n",
    "print(\"Baseline:\", baseline_metrics)\n",
    "print(\"NN      :\", nn_metrics)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed0a803",
   "metadata": {},
   "source": [
    "## 15. 误差分析（快速定位问题）\n",
    "\n",
    "- 回归：画 residual vs pred / time\n",
    "- 分类：看 confusion / top 错误样本\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e6af7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "if TASK == \"regression\":\n",
    "    resid = y_val - y_pred\n",
    "    plt.figure()\n",
    "    plt.plot(resid[:200])\n",
    "    plt.title(\"Residual (first 200)\")\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure()\n",
    "    plt.scatter(y_pred, resid, s=6)\n",
    "    plt.title(\"Residual vs Pred\")\n",
    "    plt.xlabel(\"pred\")\n",
    "    plt.ylabel(\"resid\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f45e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "if TASK in [\"binary\", \"multiclass\"]:\n",
    "    # 概率分布粗看\n",
    "    plt.figure()\n",
    "    if TASK == \"binary\":\n",
    "        plt.hist(prob, bins=50)\n",
    "        plt.title(\"Predicted P(y=1)\")\n",
    "    else:\n",
    "        plt.hist(prob.max(axis=1), bins=50)\n",
    "        plt.title(\"Max class probability\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48db38f4",
   "metadata": {},
   "source": [
    "## 16. 保存（模型 + 预处理器 + 标签编码器）\n",
    "\n",
    "- 现场通常只需要保存当前最优状态；也可直接展示结果不落盘\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e5dfee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "ART_DIR = \"artifacts\"\n",
    "os.makedirs(ART_DIR, exist_ok=True)\n",
    "\n",
    "# torch 模型\n",
    "torch.save(model.state_dict(), os.path.join(ART_DIR, \"mlp_state_dict.pt\"))\n",
    "\n",
    "# sklearn 预处理器\n",
    "joblib.dump(preprocessor, os.path.join(ART_DIR, \"preprocessor.joblib\"))\n",
    "\n",
    "# label encoder（分类）\n",
    "if label_encoder is not None:\n",
    "    joblib.dump(label_encoder, os.path.join(ART_DIR, \"label_encoder.joblib\"))\n",
    "\n",
    "print(\"Saved to:\", ART_DIR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dfa4367",
   "metadata": {},
   "source": [
    "## 17. 现场汇报用的输出（1 页）\n",
    "\n",
    "- 数据：样本量 / 时间跨度 / 缺失比例\n",
    "- Baseline 指标\n",
    "- NN 指标 + 提升幅度\n",
    "- 关键特征/误差分析发现\n",
    "- 下一步改进方向（如果还有时间）\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e4113f",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = {\n",
    "    \"n_train\": int(len(train_df)),\n",
    "    \"n_val\": int(len(val_df)),\n",
    "    \"task\": TASK,\n",
    "    \"split\": SPLIT,\n",
    "    \"baseline\": baseline_metrics,\n",
    "    \"nn\": nn_metrics,\n",
    "}\n",
    "\n",
    "summary\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
